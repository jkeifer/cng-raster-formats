{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637a32af-0f84-465b-be1d-f14347c6fe3f",
   "metadata": {},
   "source": [
    "# Reading Cloud-Optimized GeoTIFFs the Hard Way\n",
    "\n",
    "In this notebook we will explore how one can read Cloud-Optimized GeoTIFFs (COGs) the hard way, i.e., by requesting and parsing byte ranges by hand. We'll query the Earth Search STAC catalog to find an image in COG format, parse the embedded metadata and file structure out of the file, then use that information to read the bytes of an image tile from the file and process them into a usable numpy array. We'll then visualize that array in a slippy map to verify what we did got us the expected result.\n",
    "\n",
    "Before we get into it, we have to get some initial stuff out of the way, like imports and some other defs we'll need for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903800b-3eff-49c6-9ef2-6502b3afd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import dataclasses\n",
    "import enum\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import struct\n",
    "import urllib.request\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Any, Iterator, Literal, Self\n",
    "\n",
    "import folium\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import shapely\n",
    "\n",
    "from pystac_client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753dde6-9fe9-4f24-80f1-3f30cec89c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a mapping of the TIFF data types to the struct package's format charaters\n",
    "# see https://docs.python.org/3/library/struct.html#format-characters\n",
    "\n",
    "DATA_TYPES = {\n",
    "    1: '1B',  # BYTE (uint8)\n",
    "    2: '1s',  # ASCII (char[1])\n",
    "    3: '1H',  # SHORT (uint16)\n",
    "    4: '1I',  # LONG (uint32)\n",
    "    5: '2I',  # RATIONAL (uint32[2])\n",
    "    6: '1b',  # SBYTE (int8)\n",
    "    7: '1B',  # UNDEFINED (uint8)\n",
    "    8: '1h',  # SSHORT (int16)\n",
    "    9: '1i',  # SLONG (int32)\n",
    "    10: '2i',  # SRATIONAL (int32[2])\n",
    "    11: '1f',  # FLOAT (float32)\n",
    "    12: '1d',  # DOUBLE (float64)\n",
    "    13: '1I',  # SUBIFD (uint32)\n",
    "    # 14: '',\n",
    "    # 15: '',\n",
    "    16: '1Q',  # ? (uint64)\n",
    "    17: '1q',  # ? (int64)\n",
    "    18: '1Q',  # ? (uint64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1a58a-7ad4-4434-b956-0c4e9ca066d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDIANNESS = {\n",
    "    b'MM': '>',  # big endian\n",
    "    b'II': '<',  # little endian\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbd5fab-c199-4f89-9c5f-76e1a767c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_read_bytes(url: str, start: int, end: int) -> bytes:\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        headers={'Range': f'bytes={start}-{end-1}'},\n",
    "    )\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        return response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35ae14-74dc-4847-b508-b2534db8fe9a",
   "metadata": {},
   "source": [
    "## Point of Interest (POI)\n",
    "\n",
    "To give us something to use for our query, let's define a point of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c0b27-514d-408a-acd1-9b1b2652301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point of Interest\n",
    "POI = shapely.Point(-121.695833, 45.373611)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96bd917-db05-4e4f-8e23-7bcf5e90cb0f",
   "metadata": {},
   "source": [
    "It would be good if we know where this point is, don't you think? We'll use the Folium library to create a leaflet map with our point on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a33a2d-546b-4a9d-aedd-71fee5486767",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = (POI.coords[0][1], POI.coords[0][0])\n",
    "\n",
    "point_map = folium.Map(\n",
    "    location=location,\n",
    "    tiles='CartoDB positron',\n",
    "    #tiles='https://tiles.stadiamaps.com/tiles/stamen_terrain/{z}/{x}/{y}.png',\n",
    "    #attr='&copy; <a href=\"https://www.stadiamaps.com/\" target=\"_blank\">Stadia Maps</a> &copy; <a href=\"https://www.stamen.com/\" target=\"_blank\">Stamen Design</a> &copy; <a href=\"https://openmaptiles.org/\" target=\"_blank\">OpenMapTiles</a> &copy; <a href=\"https://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors',\n",
    ")\n",
    "\n",
    "folium.CircleMarker(\n",
    "    location=location,\n",
    "    fill=True,\n",
    "    fill_opacity=0.6,\n",
    ").add_to(point_map)\n",
    "\n",
    "point_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e9c2e-b33c-4924-b8f1-6fb63e04c134",
   "metadata": {},
   "source": [
    "## Querying Earth Search\n",
    "\n",
    "We'll use pystac-client to search the Earth Search Sentinel 2 L2A collection for a scene intersecting our POI. We'll aim for something with low cloud cover, in the year 2023, and we'll pick the most recent scene that matches these parameters.\n",
    "\n",
    "**WARNING**: You _can_ change this to fetch scenes from a different collection, STAC API, or not use STAC and just put in an href directly to a COG of your choosing. Doing so is STRONGLY discouraged while in the workshop, as differences in the way the file was created might be impossible to overcome within the time limits of this workshop. Consider leaving this as-is to start, and at a later date, when you have more familiarity parsing TIFFs, you can try a different source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4cc9c6-ac20-4d7c-a098-bc234b9a3858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client = Client.open(\"https://earth-search.aws.element84.com/v1\")\n",
    "\n",
    "search = client.search(\n",
    "    max_items=1,\n",
    "    collections=['sentinel-2-c1-l2a'],\n",
    "    intersects=POI,\n",
    "    datetime='2023/2023',\n",
    "    query=['eo:cloud_cover<10'],\n",
    "    sortby=[{\"direction\": \"desc\", \"field\": \"properties.datetime\"}],\n",
    ")\n",
    "item = next(search.items())\n",
    "print(json.dumps(item.to_dict(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c739c-4e2c-44f5-9689-177d2b2e2132",
   "metadata": {},
   "source": [
    "We can throw that item onto our map to see its footprint relative to our POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0f114-f70c-4449-965d-77eeda7db81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.GeoJson(item).add_to(point_map)\n",
    "point_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cede6aa-0ab0-4585-aef3-91273e75f944",
   "metadata": {},
   "source": [
    "Notably, the item we retrieved has many different bands, all of them COGs. We only need one for this exercise, so we'll grab the red band's href because that should be a good looking band visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361982ad-abb4-4c4f-829a-d537ef5b63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "href = item.assets['red'].href\n",
    "href"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6a0ce-bdd6-4e52-870a-752feea7081f",
   "metadata": {},
   "source": [
    "## The TIFF file header\n",
    "\n",
    "The first few bytes of a TIFF file tell us a couple important things we'll need to process the rest of the file. First is the endianness of the file, second is that the file is really a TIFF file.\n",
    "\n",
    "Note that not all files called `.tif` are a standard TIFF. Most notably, a standard TIFF file uses 32-bit integer offsets within the file to index particular bytes within the file (such as the offset to the first byte in an image tile, for example). Due to the maximum value of such an integer, standard TIFF files have a maximum file size of 4GB (or 2GB for certain implementations that mistakenly use _signed_ integers for offsets). To get around this limitation, the BigTIFF format was developed using 64-bit integer offsets--but this is not a standard TIFF! It is close, but different enough we're not going to worry about supporting it for our little TIFF \"library\" that we're going to build.\n",
    "\n",
    "Actually, we're not going to support a lot of things. This implementation is going to be very specific to what we need for the specific Earth Search COG we selected. That's okay: sometimes a purpose-built implementation is more performant because it doesn't have to handle all the weird edge cases. Or at least that's what we can tell ourselves as we go along and notice that we're not handling some condition we know is specific to our image in a more general way. :)\n",
    "\n",
    "### So what's in the header already?\n",
    "\n",
    "Enough jibber-jabber, let's read out the header. It's the first 4 bytes of a standard TIFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1165ed-209f-4c59-9a9e-4a3a5d5145ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = url_read_bytes(href, 0, 4)\n",
    "print(header)\n",
    "print(header.hex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2e6a5e-2d1b-4f0a-a7d0-dc1ee187d853",
   "metadata": {},
   "source": [
    "### Endianness\n",
    "\n",
    "TIFF uses the first two bytes of the file to encode the endianness of the file. This presumably enables writers to use the most efficient endianess for their host system, if needed. Readers must support reading big or little endian files, where writers can pick one endianness.\n",
    "\n",
    "Big endian is encoded as `MM` (from Motorola processors), and little endian is encoded as `II` (from Intel processors).\n",
    "\n",
    "The doubled letter is used to ensure that the characters are read the same no matter the endianness. This is because the endianness just affects the order of the bytes in the two-byte words, not the order of the bits within the bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e04d1-be87-4a2d-99db-c04e8be30b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big endian signature, unpack big endian\n",
    "print(bin(struct.unpack('>H', b'MM')[0]))\n",
    "# big endian signature, unpack little endian\n",
    "print(bin(struct.unpack('<H', b'MM')[0]))\n",
    "\n",
    "# little endian signature, unpack big endian\n",
    "print(bin(struct.unpack('>H', b'II')[0]))\n",
    "# little endian signature, unpack little endian\n",
    "print(bin(struct.unpack('<H', b'II')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b84a5e-60e2-4cbf-a454-992a319acca3",
   "metadata": {},
   "source": [
    "Note the use of the `struct` module above. This is a module from the Python stdlib that is super handy when working with binary data, as it is able to pack (Python type to binary representation) and unpack (binary representation to Python type) data values given a specific format. In the above examples, `>` and '<` designate big and little endianness, respectively. The `H` indicates that the data type is `uint16`. See the `DATA_TYPES` dict defined near the beginning of this notebook, or review [the struct docs](https://docs.python.org/3/library/struct.html) for more about its operation and the format codes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11a47b-4656-440c-8501-18ac7a2131e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our image signature\n",
    "print(header[0:2])\n",
    "endianness = ENDIANNESS[header[0:2]]  # We'll need this later, so let's save it into a var now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb20f79-ccb7-45e5-85cd-3620bb097d13",
   "metadata": {},
   "source": [
    "Note that we can check the endianness of our system rather easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbeeb4d-54ea-4cb5-b52d-92d31edcd38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.byteorder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840bede-2e10-4641-b846-7e52eea4135c",
   "metadata": {},
   "source": [
    "But note that the endianness of our system really doesn't have any bearing on how we process the data in a TIFF file. We care about endianness so we can ensure we can interpret the bytes in each word in the file in the appropriate order. Beyond that we shouldn't have to worry about endianness. Endianness is not as hard or consequential as some might have you believe (because some people have an incorrect mental model that makes handling endianness more complicated than it really is)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de25c7d-fc2c-40d7-b4aa-ddf5e6c9cbd7",
   "metadata": {},
   "source": [
    "### Magic number\n",
    "\n",
    "Many files encode a special number in their first few bytes, which can be used to distingush the files is of a given format. Wikipedia has [a big long list of these \"magic numbers\"](https://en.wikipedia.org/wiki/List_of_file_signatures) for anyone that is curious. TIFF uses the value `42` for it's magic number (and BigTIFF 43)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94e4db-7779-4ac6-a634-2917035380d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_number = struct.unpack(f'{endianness}H', header[2:4])[0]\n",
    "magic_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7831f3-186b-4402-8a41-a0c7bede61ab",
   "metadata": {},
   "source": [
    "## First IFD offset: the next four bytes\n",
    "\n",
    "Immediately following the TIFF header is the offset to the first image file directory (IFD) in the file. In a standard TIFF this offset is a 32-bit unsigned integer, as was previously alluded. We can read in and view those bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bf225-d513-4899-9a20-4837ab069686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifd_offset_bytes = url_read_bytes(href, 4, 8)\n",
    "ifd_offset_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f41ad-cf78-4168-a1fe-dea5eb91ca63",
   "metadata": {},
   "source": [
    "Though that's not super useful until we unpack those bytes into in integer (here using `I` because the offset is a `uint32` value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70828e-ef8b-4026-9c8f-ce15f13c3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifd_offset = struct.unpack(f'{endianness}I', ifd_offset_bytes)[0]\n",
    "ifd_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf82ec3-a381-4a9f-9579-a8668abf34a2",
   "metadata": {},
   "source": [
    "## Parsing the Image File Directory\n",
    "\n",
    "The Image File Directory (IFD) is a data structure composed of entries called tags (hence the name \"Tag Image File Format\"). The IFD doesn't start with the first tag entry, however. It begins with a 2-byte `unit16` value indicating the number of tags within the IFD. This value enables us, along with the IFD offset within the file, to read the entire sequence of tag bytes via `file_bytes[ifd_offset + 2:ifd_offset + (tags_count * tag_size)]`.\n",
    "\n",
    "### Tag structure\n",
    "\n",
    "In a standard TIFF, tags are a 12-byte sequence (so `tag_size` above is 12 bytes) of the following structure:\n",
    "\n",
    "| Tag Bytes | Tag field name  | Field data type |\n",
    "| --------- | --------------- | --------------- |\n",
    "| 0 - 1     | `code`          | `uint16`        |\n",
    "| 2 - 3     | `data_type`     | `uint16`        |\n",
    "| 4 - 8     | `count`         | `uint32`        |\n",
    "| 8 - 12    | `value`         | `char[4]`       |\n",
    "\n",
    "In the case of BigTIFF files, each tag is a 20-byte sequence where the `count` and `value` are of type `uint64`.\n",
    "\n",
    "The tag `code` field gives us a way to find the meaning of the tag `value`, as the `code` is an integer that maps to the tag name. The Library of Congress has [a handy table](https://www.loc.gov/preservation/digital/formats/content/tiff_tags.shtml) we can use to look up the tags by their codes.\n",
    "\n",
    "#### Tag data types\n",
    "\n",
    "The tag `data_type` is also an integer value, in this case mapping to the data type we can use to interpret `value` per the following table:\n",
    "\n",
    "| `data_type` | Type Name | Data type   |\n",
    "| ----------- | --------- | ----------- |\n",
    "| 1           | BYTE      | `uint8`     |\n",
    "| 2           | ASCII     | `char[1]`   |\n",
    "| 3           | SHORT     | `uint16`    |\n",
    "| 4           | LONG      | `uint32`    |\n",
    "| 5           | RATIONAL  | `uint32[2]` |\n",
    "| 6           | SBYTE     | `int8`      |\n",
    "| 7           | UNDEFINED | `uint8`     |\n",
    "| 8           | SSHORT    | `int16`     |\n",
    "| 9           | SLONG     | `int32`     |\n",
    "| 10          | SRATIONAL | `int32[2]`  |\n",
    "| 11          | FLOAT     | `float32`   |\n",
    "| 12          | DOUBLE    | `float64`   |\n",
    "| 13          | SUBIFD    | `uint32`    |\n",
    "| 14          | n/a       | n/a         |\n",
    "| 15          | n/a       | n/a         |\n",
    "| 16          | ?         | `uint64`    |\n",
    "| 17          | ?         | `int64`     |\n",
    "| 18          | ?         | `uint64`    |\n",
    "\n",
    "(I believe data types 16, 17, and 18 are specifc to BigTIFF, but I have so far been unable to find confirmation either way.)\n",
    "\n",
    "The `count` field tells us how many of the listed `data_type` make up the `value` of the tag. Note that even a `count` of just one for a `data_type` of, say 5, or two `uint32`s would not fit in a `value` in a standard TIFF file as `value` itself is only four bytes long. Similarly, a `count` greater than 4 with a `data_type` of 1 (`uint8`) would also be larger than can fit in `value`.\n",
    "\n",
    "In such cases where `count * len_in_bytes(data_type) > 4`, `value` itself is not actually the tag value but an offset to the actual value within the file. The length of that value is given by the previous expression `count * len_in_bytes(data_type)`. Thus, to get the actual value we can read `file_bytes[value:value + (count * len_in_bytes(data_type))]`.\n",
    "\n",
    "The IFD doesn't end with the last tag either. Each IFD contains a 4-byte (`uint32`) offset to the next IFD in the file (or 8-byte `uint64` in the case of BigTIFF). In the event an IFD is the last one in the file it will have a value of 0 for its next IFD offset. As a result, it should be possible to build a map of the complete contents of a TIFF by iterating through its IFDs and parsing their tags into some appropriate hierarchical data structure (TIFF --< IFDs --< Image segments) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffab897-313d-4edd-b2a1-3b5c8048e2d1",
   "metadata": {},
   "source": [
    "### Finding the tag count and reading the tag bytes\n",
    "\n",
    "As mentioned, an IFD starts with a 2-byte `uint16` value indicating its number of tags. If we have an IFD's offset (`ifd_offset`) within the file--which for the first IFD we know is given to us as the first bytes in the file immediately following the TIFF header--then we also know that IFS's tag offset (`tags_start`) is given by `ifd_offset + 2`.\n",
    "\n",
    "Parsing the tag count (`tags_count`) should simply be a matter of using `struct.unpack` to unpack the two tag count bytes into an integer (struct format char `H` for `uint16`). We need to make sure we use the endianness indicicated in the file header. `<` is little endian in `struct.unpack`, where `>` is big endian. Looking back, the proper endian character should have been saved into the `endianness` var for us back when we were inspecting the header bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19362c9b-f9b5-4a96-a0f1-c1ae333f5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_start = ifd_offset + 2\n",
    "tags_count = struct.unpack(f'{endianness}H', url_read_bytes(href, ifd_offset, tags_start))[0]\n",
    "tags_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8c45d-6197-4f04-9bd4-3290e674182c",
   "metadata": {},
   "source": [
    "If we know the tag count and the tag size (12 bytes for TIFF, 20 for BigTIFF), then we can find the total number of bytes in the IFD's tags by `tag_count * tag_size`. From this we should be able to find the last byte of the tags with `tags_end = tags_start + (tag_count * tag_size)`, allowing us to read the tag bytes (`tags_bytes`) from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad2762-0dbd-4d15-9b0c-336b0baf138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_size = 12  # because we only support standard TIFF\n",
    "tags_end = tags_start + (tags_count * tag_size)\n",
    "tags_bytes = url_read_bytes(href, tags_start, tags_end)\n",
    "tags_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a37331-72d2-457c-8c79-b160128e3fac",
   "metadata": {},
   "source": [
    "It's also important to note that we can use the `tags_end` to know the offset of the next IFD offset, which a 4-byte value we can unpack into a `uint32` (for a standard TIFF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d52ee-30b2-47a0-8a35-3fc4af01ed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_ifd_offset = struct.unpack(f'{endianness}I', url_read_bytes(href, tags_end, tags_end + 4))[0]\n",
    "next_ifd_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a58ef-e3e1-47d9-83d6-e286d3d1a44c",
   "metadata": {},
   "source": [
    "### Parsing each tag\n",
    "\n",
    "To parse each tag we need to find a way to split each tag's bytes out of the of the larger bytes string. Python gives us many valid ways of doing this. Let's start by using a list comprehension to split the tags bytes into a list of byte strings for each tag an see what those look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e452ccc-16cf-4898-81b9-80db88f09e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bytes_list = [tags_bytes[i*tag_size:(i*tag_size)+tag_size] for i in range(len(tags_bytes)//tag_size)]\n",
    "for tag_bytes in tag_bytes_list:\n",
    "    print(tag_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f7bd5-b714-4190-9c67-4e8532f79e33",
   "metadata": {},
   "source": [
    "#### Unpacking the tag values\n",
    "\n",
    "With a way to extract each tag's bytes, we next need to use `struct.unpack` to extract the byte values into some we can use in python for the tag's `code`, `data_type`, `count`, and `value`. Remember that `code` and `data_type` are `uint16` values, which map to the struct `H` format. Look up the proper struct format values for `count` and `value` knowing what you know about the data types of those tag fields and verify if the format passed into `struct.unpack` in the example here is correct (feel free to consult the `DATA_TYPES` dict above or the struct docs directly).\n",
    "\n",
    "For variety, this example implementation uses a `while` loop to extract the tag bytes. Each tag's fields are added into a dictionary indexed by the tag `code` to facilitate easy access in later code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81f0c7-8a03-49f9-b998-655c6dcb86a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {}\n",
    "tag_index = 0\n",
    "\n",
    "while tag_index < tags_count:\n",
    "    try:\n",
    "        tag_bytes = tags_bytes[tag_size * tag_index:(tag_size * (tag_index + 1))]\n",
    "        tag_index += 1\n",
    "    except IndexError:\n",
    "        break\n",
    "\n",
    "    code, data_type, count, value = struct.unpack(f'{endianness}HHI4s', tag_bytes)\n",
    "    tags[code] = {\n",
    "        'data_type': data_type,\n",
    "        'count': count,\n",
    "        'value': value,\n",
    "    }\n",
    "\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9c851-779a-4d6c-a0b2-7a43a6859a20",
   "metadata": {},
   "source": [
    "#### Understanding tag codes\n",
    "\n",
    "Now that we have TIFF tag values to look at, it would be good to mention the [Libray of Congress' guide to TIFF Tags](https://www.loc.gov/preservation/digital/formats/content/tiff_tags.shtml) again. We can use that lookup table to interpret each of the integer codes in a meaningful way. Note that some codes we will see in every file, while others may be specific to the way a file was encoded or the type of data it contains. Further, a number of the tags are specific to the GeoTIFF format and are required for such files, while some are used for metadata by GDAL and can generally be expected in a GeoTIFF (though not always of course).\n",
    "\n",
    "For example, we should always expect to see 256, 257, 258, and 259 (and others, these are just good examples):\n",
    "\n",
    "| Code | Tag Name      | Tag Description              |\n",
    "| ---- | ------------- | ---------------------------- |\n",
    "| 256  | ImageWidth    | Number of image columns      |\n",
    "| 257  | ImageLength   | Number of image rows         |\n",
    "| 258  | BitsPerSample | Number of bits in each pixel |\n",
    "| 259  | Compression   | Integer mapping to compression algorithm used for each image segment |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfe55d-23b1-4fd3-9f32-e1901542457d",
   "metadata": {},
   "source": [
    "#### Unpacking the tag values\n",
    "\n",
    "Recalling the earlier explanation about tag data types, counts, and values, we know that unpacking the tag values will not be the same for each tag given the differences in those three aforementioned tag fields across each of our different tags. For some tags that have a single count of a shorter data type we can unpack the tag `value` directly. But for longer values we'll have to use the tag `value` as an offset into the file to read the actual bytes to unpack.\n",
    "\n",
    "We'll start with one of these easier examples and unpack the image size tags 256 and 257. Check the data types for these tags. What are the struct format chars for each? Will we need to unpack all four bytes of the `value` for either of these tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8723a085-841e-4694-879f-28cfaba90758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image column count (width)\n",
    "cols = struct.unpack(endianness + 'H', tags[256]['value'][0:struct.calcsize('H')])[0]\n",
    "\n",
    "# image row count (height)\n",
    "# we can also resolve the struct char in a more automated fashion\n",
    "tag = tags[257]\n",
    "struct_dtype = DATA_TYPES[tag['data_type']]\n",
    "rows = struct.unpack(endianness + struct_dtype, tags[257]['value'][0:struct.calcsize(struct_dtype)])[0]\n",
    "\n",
    "print(f'Image size is {cols} x {rows}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2dd60-3b7e-414e-8d14-ca2cca6e8aea",
   "metadata": {},
   "source": [
    "In the cases where the tag `value`'s four bytes are not sufficient to contain the whole tag value, parsing is a bit more complex. We not only need to find the struct format character (`struct_dtype`) and size for the tag's data type, but then we need to:\n",
    "\n",
    "* use the data type size and the tag `count` to calculate how many bytes we need to read (`size`)\n",
    "* unpack the `value` to get the actual value's byte offset in the file (`offset`)\n",
    "* combine `size` and `offset` to get the byte range and read that out fo the file (giving us `values`)\n",
    "* build the struct format string (`endianness + (struct_dtype * count)`) then unpack `values`\n",
    "\n",
    "We'll preview this here with an example unpacking the tile offsets tag (324). The values we get out of this (`tile_offsets`) are the byte offsets for each image segment (tile) in the image represented by this IFD. We will be able to use these offsets in the next section to read the specific tile containing our POI (though we'll have unpack the rest of our tags and do a bit of math to figure out which one and what to do with the bytes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e6e581-3a51-444a-b90f-20d94e19fc41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tag = tags[324]\n",
    "struct_dtype = DATA_TYPES[tag['data_type']]\n",
    "size = tag['count'] * struct.calcsize(struct_dtype)\n",
    "offset = struct.unpack(f'{endianness}I', tag['value'])[0]\n",
    "values = url_read_bytes(href, offset, offset+size)\n",
    "tile_offsets = struct.unpack(endianness + (struct_dtype * tag['count']), values)\n",
    "\n",
    "for idx, tile_offset in enumerate(tile_offsets):\n",
    "    print(f\"Offset tile {idx}: {tile_offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde6490-a49f-4014-b981-035e7ff5c170",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Refer back to the STAC item and see if the `file` STAC extension is in use. Is the file size listed for the COG asset your are examining, and if so how close to the end of the file do these tiles appear to get?\n",
    "* Can you use the unpacking examples to create a generalized approach to unpacking the tag values and apply that to the rest of the tags in the IFD? The next section will have you unpack all the tags, so finding a quick an efficient way to do this might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc1666-70bb-4486-9b6a-5f3768f0b278",
   "metadata": {},
   "source": [
    "## Reading a tile from the image\n",
    "\n",
    "Read the tile intersecting our POI will require most of our tags to be unpacked and decoded. Refer back to the tags dictionary `tags` keys for the list of all tag codes in our TIFF's first IFD and the above documentation on the tag codes. Then, using the patterns demonstrated above for unpacking the tag values (or a more efficient function/implementation of your own), unpack each tag's value into the corresponding variable name in the list below:\n",
    "\n",
    "* `image_width`\n",
    "* `image_length`\n",
    "* `bits_per_sample`\n",
    "* `compression`\n",
    "* `samples_per_pixel`\n",
    "* `predictor`\n",
    "* `tile_width`\n",
    "* `tile_length`\n",
    "* `tile_offsets`\n",
    "* `tile_byte_counts`\n",
    "* `sample_format`\n",
    "* `pixel_scale`\n",
    "* `tie_point`\n",
    "* `geo_key_directory`\n",
    "* `geo_double_params` (if defined, else `tuple()`)\n",
    "* `geo_ascii_params` (if defined, else `b''`)\n",
    "* `gdal_metadata`\n",
    "* `nodata_value`\n",
    "\n",
    "**NOTE**: if you have chosen a different COG source than the default Sentinel 2 red band from Earth Search, you might need to consider additional tags and processing to get this part to work. TIFF is an extremely flexible format, but this means it has many different cases that need to be handled to be able to read any arbitrary file (which also means some atypical features supported by one implementation might lead to incompatibilities with other implementations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ec6a1-3724-4fa7-ad23-c2be84b5bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the above list of variables here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f1870-d918-4bbb-be17-147392f10736",
   "metadata": {},
   "source": [
    "### Interpreting tag values\n",
    "\n",
    "Many of the tags are straightforward. Some are enumerations which require an external lookup table. Others require cross-references between their values to make sense of the contents. Let's take a look at the few that are not straightforward to understand.\n",
    "\n",
    "#### Compression\n",
    "\n",
    "The `compression` tag value represents one of an enumerated set of possible compression methods. Continuing with the spirit of needing to consult various external lookup tables, the [Wikipedia entry for TIFF has a great table of possible compression formats and their integer values](https://en.wikipedia.org/wiki/TIFF#TIFF_Compression_Tag) is a great resource for understanding the meaning of the different possible values.\n",
    "\n",
    "**Question**: What is the value of the `compression` tag and what compression scheme does it indicate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458b1cf-d6e0-4195-b05d-735ce40c97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f68597c-873d-403a-80bc-e58a245f13cb",
   "metadata": {},
   "source": [
    "#### Sample format\n",
    "\n",
    "The `sample_format` tag value represents one of an enumerated set of possible data types. Those values map as follows:\n",
    "\n",
    "| Format Value | Data Type |\n",
    "| ------------ | --------- |\n",
    "| 1 | `uint`   |\n",
    "| 2 | `int`    |\n",
    "| 3 | `float`  |\n",
    "| 4 | untyped  |\n",
    "| 5 | `cint`   |\n",
    "| 6 | `cfloat` |\n",
    "\n",
    "The bit depth of the specified format is dependent on the value of the `bits_per_sample` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f18e5b-05a3-4153-a010-16b589e31bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_format, bits_per_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ffc5c-74f8-4d9e-ae1d-c10306b34a4b",
   "metadata": {},
   "source": [
    "**Question**: What does the value of the `sample_format` tag indicate with regards to the data type and length of the cell values in this image (e.g., `uint32`, `int8`, `float32`, etc.)? What does this data type map to in the struct format characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73190c20-4600-45fb-9df8-333a9b4d050f",
   "metadata": {},
   "source": [
    "#### Pixel scale and tie point\n",
    "\n",
    "The `pixel_scale` tag is part of the GeoTIFF specification. It is a three-tuple where each value represents one dimension of the pixel scale, specifically the x, y, and z scales, respectively. In other words, each of the scale values represent the change in coordinate from one pixel origin to the next along the specified dimension. The units of each scale value are the same as those specified in coordinate reference system (CRS; we'll see this when reviewing the `geo_key_directory` below).\n",
    "\n",
    "The `tie_point` tag is again a member of the GeoTIFF specification. It defines a coordiante in the image space and its mapping to the model space as a six-tuple. The first three tuple values are the image space x, y, and z coordinates, respectively. The latter three tuple values are the model space x, y, and z, respectively. The model space is perhaps best understood to be the coordinate reference system defined for the image. Almost always the image space coordinate is 0, 0, 0, which effectively allows us to consider the model space coordiantes to be the geographic point represented by the image origin.\n",
    "\n",
    "The actual GeoTIFF spec docs detailing how to use these values are [here](http://geotiff.maptools.org/spec/geotiff2.6.html).\n",
    "\n",
    "Perhaps most notable for us is that we can build an affine transform for the image in the same format as [GDAL's geotransform](https://gdal.org/en/latest/tutorials/geotransforms_tut.html) using the following relations:\n",
    "\n",
    "```python\n",
    "geotransform = (\n",
    "    # x-coordinate of the upper-left corner of the upper-left pixel (origin)\n",
    "    tie_point[3] - (pixel_scale[0] * tie_point[0]),\n",
    "    # w-e pixel resolution / pixel width\n",
    "    pixel_scale[0],\n",
    "    # row rotation (typically zero)\n",
    "    0,\n",
    "    # y-coordinate of the upper-left corner of the upper-left pixel (origin)\n",
    "    tie_point[4] - (-pixel_scale[1] * tie_point[1]),\n",
    "    # column rotation (typically zero)\n",
    "    0,\n",
    "    # n-s pixel resolution / pixel height (negative value for a north-up image)\n",
    "    -pixel_scale[1],\n",
    ")\n",
    "```\n",
    "\n",
    "Note that in the general case of `tie_point[:3]` being `(0, 0, 0)` we see that `geotransform[0] = tie_point[4]` and `geotransform[3] = tie_point[5]`. Also note that these two tags cannot be used to represent grid rotations. In cases where this needs to be considered the `ModelTransformationTag` will be present instead (we'll leave out the details around the use of this tag for brevity/simplicity, but the [GeoTIFF spec docs](http://geotiff.maptools.org/spec/geotiff2.6.html) can be consulted if needed to understand this tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e102bf-5231-4d87-8373-7fa534fbf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geotransform = (\n",
    "    # x-coordinate of the upper-left corner of the upper-left pixel (origin)\n",
    "    tie_point[3] - (pixel_scale[0] * tie_point[0]),\n",
    "    # w-e pixel resolution / pixel width\n",
    "    pixel_scale[0],\n",
    "    # row rotation (typically zero)\n",
    "    0,\n",
    "    # y-coordinate of the upper-left corner of the upper-left pixel (origin)\n",
    "    tie_point[4] - (-pixel_scale[1] * tie_point[1]),\n",
    "    # column rotation (typically zero)\n",
    "    0,\n",
    "    # n-s pixel resolution / pixel height (negative value for a north-up image)\n",
    "    -pixel_scale[1],\n",
    ")\n",
    "geotransform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1622de3-a4ca-4f41-a5b2-eb0a09f15b6d",
   "metadata": {},
   "source": [
    "Does the above geotransform result match your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46017e-0bf0-4a4f-bea5-61a23729c884",
   "metadata": {},
   "source": [
    "#### Geo key directory and the params\n",
    "\n",
    "Another set of GeoTIFF-spec tags, `geo_key_directory`, `geo_double_params`, and `geo_ascii_params` represent a collection of geospatial information we need to interpret the data in a spatially-aware way. For example, such important information as the CRS is stored amongst these tags. The [GeoTIFF spec docs also document these tags and their interactions](http://geotiff.maptools.org/spec/geotiff2.4.html).\n",
    "\n",
    "In short, `geo_double_params` and `geo_ascii_params` are actually sets of parameters that can be used to fill in information that cannot be represented directly in the `geo_key_directory` due to data type differences (the latter is a `uint16` tuple whereas the former two are tuples of double precision floats and ASCII-encoded strings, respectively). The `geo_key_directory` is a collection of four-tuples (potentially with some additional trailing values), the first of which is a header that documents the tuples that follow. It has the following 8-byte structure:\n",
    "\n",
    "```\n",
    "Header = (KeyDirectoryVersion, KeyRevision, MinorRevision, NumberOfKeys)\n",
    "```\n",
    "\n",
    "For our purposes, the important piece here are the number of keys: we need to know how many keys are in the directory to be able to work out the offset to any additional values in the directory structure we might need to fill in directory entries that have multiple `unit16` values.\n",
    "\n",
    "After the header, each of the keys in the directory have the 8-byte structure:\n",
    "\n",
    "```\n",
    "KeyEntry = (KeyID, TIFFTagLocation, Count, Value_Offset)\n",
    "```\n",
    "\n",
    "The `KeyID` here is just like our TIFF tags: it is an identifier that can be used with an external lookup table to interpret the meaning of the key's value. The `TIFFTagLocation` is used to point to a TIFF tag that contains the value for this key: if the value is directly embedded in the key (in the place of `Value_Offset`) then the location is `0` and this key's value is of type `uint16`. In cases where the value is not directly embedded in the key the location will have the value of the tag code that contains the value. The `Value_Offset` and `Count` can then be used to extract the set of values pertaining to this key from that tag's data. The data type of the key value is given by the source tag's data type.\n",
    "\n",
    "For example, if we have a key entry with the values `(1024, 0, 1, 1)` we know that the key ID is `1024`, the location of `0` means the value is embedded in the key entry, and that means our count is necessarily `1` and we can interpret the `Value_Offset` as the key value, in this case `1`.\n",
    "\n",
    "A more complex example could be like `(2049, 34737, 7, 22)`: in this case we have a non-zero location, so we have to read the values--in this case seven values per the count value--from a separate tag. The location of `34737` corresponds to the `geo_ascii_params` tag, which not only tells us where to get the values for this key, but also their data type. If we have a value of the `34737` tag of `b'WGS 84 / UTM zone 10N|WGS 84|\\x00'`, then taking 7 bytes from position 22 we end up with `b'WGS 84|'`. The `|` is intended to be converted into a null byte to terminate the extracted string; in Python it is easy enough to read one less byte than the key's count for ASCII-type keys as string termination is handled for us.\n",
    "\n",
    "We can use the above explanation to write a general-purpose function to extract the keys into a dict, like we originally did with the IFD tags, and then we can use it to extract our keys. Refer to the [GeoTIFF document \"Geocoding Raster Data\"](http://geotiff.maptools.org/spec/geotiff2.7.html#2.7) for and explanantion of the key IDs and how to understand their meanings. These keys are critical for finding the CRS of the file via the information presented in that documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf68fb-ee82-4f40-8fb7-e02618a55968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geo_keys(\n",
    "    key_directory: tuple[int, ...],\n",
    "    double_params: tuple[float, ...],\n",
    "    ascii_params: bytes,\n",
    ")-> dict[int, int | float | bytes]:\n",
    "    keys: dict[int, int | float | bytes] = {}\n",
    "    \n",
    "    try:\n",
    "        _, _, _, key_count = key_directory[0:4]\n",
    "        for key_index in range(key_count):\n",
    "            offset = (4 * key_index) + 4\n",
    "            key_id, location, count, value_offset = key_directory[offset:offset + 4]\n",
    "            \n",
    "            if location == 0:\n",
    "                keys[key_id] = value_offset\n",
    "            elif location == 34735:\n",
    "                keys[key_id] = key_directory[value_offset:value_offset + count]\n",
    "            elif location == 34736:\n",
    "                keys[key_id] = double_params[value_offset:value_offset + count]\n",
    "            elif location == 34737:\n",
    "                keys[key_id] = ascii_params[value_offset: value_offset + (count - 1)]\n",
    "            else:\n",
    "                raise ValueErorr(f'Unknown location: {location}')\n",
    "    except:\n",
    "        raise ValueError('Could not parse geo keys')\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7a95e-5198-4d42-9d99-aa0e15df32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_keys = extract_geo_keys(geo_key_directory, geo_double_params, geo_ascii_params)\n",
    "geo_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51045882-2605-4cea-90ce-18d63c6dc5a7",
   "metadata": {},
   "source": [
    "**Question**: From the extracted geo key values, can you find the CRS and it's EPSG code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64deb076-42f0-47af-891b-611b29668dc2",
   "metadata": {},
   "source": [
    "#### Nodata\n",
    "\n",
    "The GDAL nodata value is stored in GeoTIFFs as a null-terminated ASCII string, for some reason (likely to ensure it can be parsed with a consistent data type, in particular because the nodata value needs to be interpreted with the data type of the TIFF data, which might not map directly to the TIFF-defined data types). Because of this, the `nodata` value needs some additional processing before we can use it.\n",
    "\n",
    "Specifically, we need to clip the final character off, then we need to cast it to an appropropriate data type (as given by `sample_format` and `bits_per_sample`). For example, if we have an integer data type for our image data then we need to do something like `nodata_value = int(original_nodata_value[:-1])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5e38a-c480-4433-a8f6-4fd2e3e9bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clip the string terminator off the nodata value\n",
    "# before coercing to an int (because it is stored as ASCII)\n",
    "nodata_value = int(original_nodata_value[:-1])\n",
    "nodata_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d92de-223e-4f31-89bd-f07c85b67633",
   "metadata": {},
   "source": [
    "## Reading an image tile\n",
    "\n",
    "Now that we have all our metadata parsed out we can focus on using that metadata to read a tile. We have our POI though, so we presumably want to find the tile containing said POI, rather than some other arbitrary tile. To do so we'll need to do some math.\n",
    "\n",
    "### Transforming our POI\n",
    "\n",
    "First, we need to find the point coordinates of our POI in the same reference system as the image. We can use `pyproj` to do the coordinate transform, as we know our POI is defined as long/lat in EPSG:4326, and we should be able to get our image's CRS from geo keys we parsed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f464f82-5ae4-4d50-a60b-bde85d03238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = pyproj.Transformer.from_crs(\"EPSG:4326\", \"EPSG:32610\")\n",
    "transformed_x, transformed_y = transformer.transform(POI.y, POI.x)\n",
    "print(f'x={transformed_x}, y={transformed_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842480d-530b-427d-aafc-1268255e021f",
   "metadata": {},
   "source": [
    "Check the above output. Does it make sense given what we know about the origin of our image, and the relation of our POI to the image footprint?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b166f9-13e2-4084-b59c-51bd536e33cb",
   "metadata": {},
   "source": [
    "### Finding the pixel coordinates of our POI\n",
    "\n",
    "Now that we have our POI geographic coordinates in the same CRS as our image, we can use the image's geotransform to convert our POI's geographic coordinates into pixel coordinates in our image's pixel grid. This is a fairly straightforward mapping given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cba895-b4d9-4759-9565-d3df74e03a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = int((transformed_x - geotransform[0]) // geotransform[1])\n",
    "row = int((transformed_y - geotransform[3]) // geotransform[5])\n",
    "print(f'col={col}, row={row}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9a1fd-a759-4683-93cb-38303d6a74f8",
   "metadata": {},
   "source": [
    "Again, check the above output. Does it make sense given what we know about the origin of our image, its grid, and the relation of our POI to the image footprint?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29697e92-2742-4154-883b-1fefa11285b3",
   "metadata": {},
   "source": [
    "### Finding our tile coordinates\n",
    "\n",
    "To work out which tile we need to read we need to convert our pixel coordinates into tile coordinates. This can be done rather simply if we know the size of our tiles, which we do because of the values from the `tile_width` and `tile_length` tags, via division:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fafb5c-dcd2-4e96-930b-e8b309a440fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_col = col // tile_width\n",
    "tile_row = row // tile_length\n",
    "print(f'tile_col={tile_col}, tile_row={tile_row}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d35d4-294c-44da-93c9-0d9152f97ac9",
   "metadata": {},
   "source": [
    "One last time: check the above output. Does it make sense given what we know about the structure our image, and the relation of our POI to the image footprint?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788a090-6288-4925-963d-5e255cff3621",
   "metadata": {},
   "source": [
    "### Finding our tile offset and byte length\n",
    "\n",
    "The tag values of `tile_offsets` and `tile_byte_counts` give us the offset and byte lengths of each tile. To retrive them for a given tile we need to know the tile's index within those tuples. Converting any arbitrary tile's coordinates to it's index is given by `(ceiling(image_width / tile_width) * tile_row) + tile_col`. Once we have that index we just need to grab the values from `tile_offsets` and `tile_byte_counts` to have the tile offset and tile byte length, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f428e-3fc3-4e43-a660-4ca0d5277818",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_index = (math.ceil(image_width / tile_width) * tile_row) + tile_col\n",
    "tile_offset = tile_offsets[tile_index]\n",
    "tile_byte_length = tile_byte_counts[tile_index]\n",
    "print(f'tile ({tile_col}, {tile_row}) has index {tile_index} and is at offset {tile_offset} with length {tile_byte_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade2970-ee62-40f4-bbaf-012a504c330f",
   "metadata": {},
   "source": [
    "### Actually reading the tile\n",
    "\n",
    "Now that we know where the tile bytes are in the file we can read them, extract them (using the specified `compression`), then unpack them into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aec812-f6f1-4339-96e9-2d803b6e5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_bytes = url_read_bytes(href, tile_offset, tile_offset + tile_byte_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db4c1d-ac5b-4596-b5c2-a71127f6c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per our `compression` tag we know we the data is compressed using `DEFLATE`,\n",
    "# which can be extracted using the stdlib `zlib` module.\n",
    "import zlib\n",
    "tile_extracted = zlib.decompress(tile_bytes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f8da5-6364-4443-994e-3fcc5570c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.frombuffer(tile_extracted, dtype=np.uint16).reshape(tile_width, tile_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a34ce2-5380-4669-a498-75c0f8d100c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data type is `uint16` as we previously found; using our\n",
    "# lookup table we know that maps to a struct format char of `H`.\n",
    "# That dtype is 2-bytes in length, so we know our tile data\n",
    "# contains `len(tile_extracted) // 2` pixel values.\n",
    "struct_dtype = 'H'\n",
    "tile_array = np.array(\n",
    "    struct.unpack(\n",
    "        endianness + (struct_dtype * (len(tile_extracted) // struct.calcsize(struct_dtype))),\n",
    "        tile_extracted,\n",
    "    ),\n",
    "    dtype=np.uint16\n",
    ").reshape(tile_width, tile_length)\n",
    "tile_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449315e-939c-46ef-82b0-51a36d092ab6",
   "metadata": {},
   "source": [
    "#### A note on `predictor`\n",
    "\n",
    "The `predictor` tag is used when a filtering step is done prior to compression. For geospatial data, values of `2` and `3` are common, `2` is best for integer data, and calculates the horizontal difference between cells. `3` is used for floating point data. In other words, if we have a predictor set and it isn't `1` (indicating no predictor) then we can't just extract the data and start using it. The data will require processing step to reverse the prediction operation and restore the data back to its original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106632b4-0d93-42f2-97e3-c1d6a338b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094e1f2-cb8d-4f1a-bbc8-de44eb2aed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as our data is using predictor `2` (horizontal difference),\n",
    "# we'll need to reverse the difference using a cumulative sum\n",
    "tile_array_unfiltered = np.cumsum(tile_array, axis=1, dtype=tile_array.dtype)\n",
    "tile_array_unfiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965bb9c-ef6c-43ef-aacb-d51fea252033",
   "metadata": {},
   "source": [
    "#### Scale and offset\n",
    "\n",
    "We have yet one more operation we need to do to our data array to make it usable. It turns out the stored data format `uint16` isn't actually the real data format. Instead, limited-precision floats have been mapped to that data type by using a specified scaling factor. Moreover, due to the Sentinel 2 L2 atmospheric correction process, it's possible to have negative values in the data, which must be accounted for by shifting the uint values via a specified offset.\n",
    "\n",
    "Both the `scale` and `offset` values are contained within the `gdal_metadata` tag. The GDAL metadata format is, sadly, XML, though for our purposes it is readable enough we don't need to worry about parsing complexities, we can just print out the value of that tag and read out the values we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d7cb4-928d-45fa-bbc2-8c1b2ab020b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdal_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b1c67-8708-4549-a4b1-d2b434035d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the value_offset and value_scale from the above\n",
    "value_offset = ?\n",
    "value_scale = ?\n",
    "tile_array_scaled_offset = (tile_array_unfiltered * value_scale) + value_offset\n",
    "tile_array_scaled_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d22864-6684-47c4-b533-fdd0ffc5bdd3",
   "metadata": {},
   "source": [
    "## Visualizing the tile on our map\n",
    "\n",
    "Now that we have our tile data, it would be great to see it alongside our POI to visually confirm we got the tile we expected. It turns out Folium has a kinda hokey way of converting numpy arrays to PNGs for display on the map, which we can leverage here to visually verify the data we've read for our tile and the operations we've done on it. It's not perfect, as it assumes our data is aligned to the mercator grid (which it probably isn't), but it's close enough for us to take a look.\n",
    "\n",
    "We just need the tile's min and max latitude and longitude (in EPSG:4326 coordinates) so we can tell Folium it's bounding box (roughly), then we can (re-)make our map and add our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f77340-a5df-466f-8dec-a9b8ca82cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's find the origin of our tile (upper left)\n",
    "tile_origin_x = geotransform[0] + (tile_col * tile_width * geotransform[1])\n",
    "tile_origin_y = geotransform[3] + (tile_row * tile_length * geotransform[5])\n",
    "tile_origin_x, tile_origin_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c966c-a764-45e7-8790-af7693ab9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then let's find the transformed coordinates of the upper left and bottom right corners\n",
    "to_4326_transformer = pyproj.Transformer.from_crs(\"EPSG:32610\", \"EPSG:4326\")\n",
    "\n",
    "# upper left corner\n",
    "max_lat, min_long = to_4326_transformer.transform(\n",
    "    tile_origin_x,\n",
    "    tile_origin_y,\n",
    ")\n",
    "# bottom right corner\n",
    "min_lat, max_long = to_4326_transformer.transform(\n",
    "    tile_origin_x + ((tile_width + 1) * geotransform[1]),\n",
    "    tile_origin_y + ((tile_length + 1) * geotransform[5]),\n",
    ")\n",
    "(min_lat, min_long), (max_lat, max_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069efff8-060b-4cd9-b1a2-a3d2655158e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we make a whole new map because if we screwed\n",
    "# something up we only have to re-run this cell to fix it\n",
    "raster_map = folium.Map(\n",
    "    location=location,\n",
    "    tiles='CartoDB positron',\n",
    ")\n",
    "\n",
    "folium.CircleMarker(\n",
    "    location=location,\n",
    "    fill=True,\n",
    "    fill_opacity=0.6,\n",
    ").add_to(raster_map)\n",
    "\n",
    "folium.GeoJson(item).add_to(raster_map)\n",
    "\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    tile_array_scaled_offset,\n",
    "    bounds=[[min_lat, min_long], [max_lat, max_long]],\n",
    "    name='tile',\n",
    ").add_to(raster_map)\n",
    "\n",
    "folium.LayerControl().add_to(raster_map)\n",
    "\n",
    "raster_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f709856-e51b-41fe-9936-adc0139d1ab3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Additional exercises to consider later\n",
    "\n",
    "* Find how many overviews are in this file.\n",
    "* Find the dimensions and gsd of each overview.\n",
    "* Repeat reading the tile containing your point of interest, but do so from one of the overviews.\n",
    "* How can we make reading the file more efficient? Can we get all the IFDs in the file with a single read without having to read in image data?\n",
    "* Can you write the TIFF for the map visualization yourself instead of using an external lib?\n",
    "* Repeat these exercises with a multiband TIFF to see how the file structure differs to support the additional bands.\n",
    "\n",
    "Any other cool ideas? Let me know and/or share with the group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
