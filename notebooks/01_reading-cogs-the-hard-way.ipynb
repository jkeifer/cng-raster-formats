{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637a32af-0f84-465b-be1d-f14347c6fe3f",
   "metadata": {},
   "source": [
    "# Reading Cloud-Optimized GeoTIFFs the Hard Way\n",
    "\n",
    "In this notebook we will explore how one can read Cloud-Optimized GeoTIFFs (COGs) the hard way, i.e., by requesting and parsing byte ranges by hand. We'll query the Earth Search STAC catalog to find an image in COG format, parse the embedded metadata and file structure out of the file, then use that information to read the bytes of an image tile from the file and process them into a usable numpy array. We'll then visualize that array in a slippy map to verify what we did got us the expected result.\n",
    "\n",
    "Before we get into it, we have to get some initial stuff out of the way, like imports and some other defs we'll need for later."
   ]
  },
  {
   "cell_type": "code",
   "id": "7903800b-3eff-49c6-9ef2-6502b3afd9f5",
   "metadata": {},
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import dataclasses\n",
    "import enum\n",
    "import json\n",
    "import struct\n",
    "import urllib.request\n",
    "\n",
    "from pprint import pprint\n",
    "from typing import Any, Iterator, Literal, Self, TypedDict\n",
    "\n",
    "import folium\n",
    "import numpy as np\n",
    "\n",
    "from griffine import Affine, Grid\n",
    "from odc.geo.geom import point\n",
    "from pystac_client import Client"
   ]
  },
  {
   "cell_type": "code",
   "id": "9753dde6-9fe9-4f24-80f1-3f30cec89c8f",
   "metadata": {},
   "source": [
    "# This is a mapping of the TIFF data types to the struct package's format charaters\n",
    "# see https://docs.python.org/3/library/struct.html#format-characters\n",
    "\n",
    "DATA_TYPES = {\n",
    "    1: 'B',  # BYTE (uint8)\n",
    "    2: 's',  # ASCII (char[1])\n",
    "    3: 'H',  # SHORT (uint16)\n",
    "    4: 'I',  # LONG (uint32)\n",
    "    5: 'II',  # RATIONAL (uint32[2])\n",
    "    6: 'b',  # SBYTE (int8)\n",
    "    7: 'B',  # UNDEFINED (uint8)\n",
    "    8: 'h',  # SSHORT (int16)\n",
    "    9: 'i',  # SLONG (int32)\n",
    "    10: 'ii',  # SRATIONAL (int32[2])\n",
    "    11: 'f',  # FLOAT (float32)\n",
    "    12: 'd',  # DOUBLE (float64)\n",
    "    13: 'I',  # SUBIFD (uint32)\n",
    "    # 14: '',\n",
    "    # 15: '',\n",
    "    16: 'Q',  # ? (uint64)\n",
    "    17: 'q',  # ? (int64)\n",
    "    18: 'Q',  # ? (uint64)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "id": "1df1a58a-7ad4-4434-b956-0c4e9ca066d3",
   "metadata": {},
   "source": [
    "EPSG_4326 = 'EPSG:4326'\n",
    "\n",
    "ENDIANNESS = {\n",
    "    b'MM': '>',  # big endian\n",
    "    b'II': '<',  # little endian\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "id": "3bbd5fab-c199-4f89-9c5f-76e1a767c330",
   "metadata": {},
   "source": [
    "def binary(_bytes: bytes, join_str: str = ' ') -> None:\n",
    "    _hex = _bytes.hex()\n",
    "    return join_str.join([\n",
    "        '{:08b}'.format(int(_hex[i:i+2], 16))\n",
    "        for i in range(0, len(_hex), 2)\n",
    "    ])\n",
    "\n",
    "def url_read_bytes(url: str, start: int, end: int) -> bytes:\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        headers={'Range': f'bytes={start}-{end-1}'},\n",
    "    )\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        return response.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35ae14-74dc-4847-b508-b2534db8fe9a",
   "metadata": {},
   "source": [
    "## Point of Interest (POI)\n",
    "\n",
    "To give us something to use for our query, let's define a point of interest."
   ]
  },
  {
   "cell_type": "code",
   "id": "70a33a2d-546b-4a9d-aedd-71fee5486767",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Point of Interest\n",
    "POI = point(-121.695833, 45.373611, crs=EPSG_4326)\n",
    "\n",
    "# Let's find out where the point is\n",
    "point_map = POI.explore(name='point')\n",
    "point_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e9c2e-b33c-4924-b8f1-6fb63e04c134",
   "metadata": {},
   "source": [
    "## Querying Earth Search\n",
    "\n",
    "We'll use pystac-client to search the Earth Search Sentinel 2 L2A collection for a scene intersecting our POI. We'll aim for something with low cloud cover, in the year 2023, and we'll pick the most recent scene that matches these parameters.\n",
    "\n",
    "**WARNING**: You _can_ change this to fetch scenes from a different collection, STAC API, or not use STAC and just put in an href directly to a COG of your choosing. Doing so is discouraged while in the workshop, as differences in the way the file was created might be impossible to overcome within the time limits of this workshop. Consider leaving this as-is to start, and at a later date, when you have more familiarity parsing TIFFs, you can try a different source."
   ]
  },
  {
   "cell_type": "code",
   "id": "6a4cc9c6-ac20-4d7c-a098-bc234b9a3858",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "client = Client.open(\"https://earth-search.aws.element84.com/v1\")\n",
    "\n",
    "search = client.search(\n",
    "    max_items=1,\n",
    "    collections=['sentinel-2-c1-l2a'],\n",
    "    intersects=POI,\n",
    "    datetime='2023/2023',\n",
    "    query=['eo:cloud_cover<10'],\n",
    "    sortby=[{\"direction\": \"desc\", \"field\": \"properties.datetime\"}],\n",
    ")\n",
    "item = next(search.items())\n",
    "print(json.dumps(item.to_dict(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c739c-4e2c-44f5-9689-177d2b2e2132",
   "metadata": {},
   "source": [
    "We can throw that item onto our map to see its footprint relative to our POI."
   ]
  },
  {
   "cell_type": "code",
   "id": "f3a0f114-f70c-4449-965d-77eeda7db81d",
   "metadata": {},
   "source": [
    "stac_item_layer = folium.GeoJson(item, name='stac-item-footprint')\n",
    "point_map.fit_bounds(stac_item_layer.get_bounds())\n",
    "stac_item_layer.add_to(point_map)\n",
    "\n",
    "point_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cede6aa-0ab0-4585-aef3-91273e75f944",
   "metadata": {},
   "source": [
    "Notably, the item we retrieved has many different bands, all of them COGs. We only need one for this exercise, so we'll grab the red band's href because that should be a good looking band visually."
   ]
  },
  {
   "cell_type": "code",
   "id": "361982ad-abb4-4c4f-829a-d537ef5b63ae",
   "metadata": {},
   "source": [
    "href = item.assets['red'].href\n",
    "print(href)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6a0ce-bdd6-4e52-870a-752feea7081f",
   "metadata": {},
   "source": [
    "## The TIFF file header\n",
    "\n",
    "The first few bytes of a TIFF file tell us a couple important things we'll need to process the rest of the file. First is the endianness of the file, second is that the file is really a TIFF file.\n",
    "\n",
    "Note that not all files with a `.tif` extension are a standard TIFF. Most notably, a standard TIFF file uses 32-bit integer offsets within the file to index particular bytes within the file (such as the offset to the first byte in an image tile, for example). Due to the maximum value of such an integer, standard TIFF files have a maximum file size of 4GB (or 2GB for certain archiac implementations that mistakenly used _signed_ integers for offset values). To get around this limitation, the BigTIFF format was developed using 64-bit integer offsets--but this is not a standard TIFF! It is close, but different enough we're not going to worry about supporting it for our little TIFF \"library\" that we're going to build.\n",
    "\n",
    "Actually, we're not going to support a lot of things. This implementation is going to be very specific to what we need for the specific Earth Search COG we selected. That's okay: sometimes a purpose-built implementation is more performant because it doesn't have to handle all the weird edge cases. Or at least that's what we can tell ourselves to feel better as we go along and notice how many conditions we're not handling in a more general way.\n",
    "\n",
    "### So what's in the header already?\n",
    "\n",
    "Enough jibber-jabber, let's read out the header. It's the first 4 bytes of a standard TIFF."
   ]
  },
  {
   "cell_type": "code",
   "id": "6e1165ed-209f-4c59-9a9e-4a3a5d5145ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell0)"
  },
  {
   "cell_type": "markdown",
   "id": "7c2e6a5e-2d1b-4f0a-a7d0-dc1ee187d853",
   "metadata": {},
   "source": [
    "### Endianness and the TIFF Byte-Order Mark\n",
    "\n",
    "TIFF uses the first two bytes of the file to encode the endianness of the file as the \"Byte-Order Mark\". This presumably enables writers to use the most efficient endianess for their host system, if needed. Readers must support reading big or little endian files, where writers can pick one endianness.\n",
    "\n",
    "We can consider the endianness of a TIFF file to \"describe the order of the bytes in a multi-byte data type\". That is, when we have a 16-, 32-, or 64-bit value, the endianness tells how to interpret which bytes are most- and least-signifcant. In the case of a 32-bit integer value, that looks like this:\n",
    "\n",
    "```\n",
    "16^1\n",
    "|16^0\n",
    "|| 16^3\n",
    "|| |16^2\n",
    "|| || 16^5\n",
    "|| || |16^4\n",
    "|| || || 16^7\n",
    "|| || || \u23ae16^6\n",
    "C0 00 00 00    = 192  little endian (II)\n",
    "\n",
    "00 00 00 C0    = 192  big endian (MM)\n",
    "|| || || \u23ae16^0\n",
    "|| || || 16^1\n",
    "|| || |16^2\n",
    "|| || 16^3\n",
    "|| |16^4\n",
    "|| 16^5\n",
    "|16^6\n",
    "16^7\n",
    "```\n",
    "\n",
    "Big endian is encoded as the byte-order mark `MM` (from Motorola processors), and little endian is encoded as `II` (from Intel processors).*\n",
    "\n",
    "The doubled letter is used to ensure that the binary sequence is the same no matter the endianness. Again, this is because the endianness affects only the order of the bytes in that two-byte word, not the order of the bits within each of the bytes.\n",
    "\n",
    "----\n",
    "\n",
    "*Naively, the above example might make it seem silly to use little endian notation--big endian seems much more natural, given the way we generally have been taught to read and write numbers. However, when it comes to how most microprocessors and memory operations actually work, little endian has some clear benefits which has generally led to its dominance outside networking. More of the nuance and complication of endianness is well documented on [its wikipedia page](https://en.wikipedia.org/wiki/Endianness)."
   ]
  },
  {
   "cell_type": "code",
   "id": "1f11a47b-4656-440c-8501-18ac7a2131e4",
   "metadata": {},
   "source": [
    "endianness = ENDIANNESS[header[0:2]]  # We'll need this later, so let's save it into a var now\n",
    "print(f\"Endianness signature: {header[0:2]}; struct endianness format char: '{endianness}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337dd030-79fd-42fb-aec9-91743258ee20",
   "metadata": {},
   "source": [
    "To reiterate this point about endianness: we care about endianness so we can ensure we can interpret the bytes in each word in the file in the appropriate order. Beyond that we aren't going to need to worry about endianness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de25c7d-fc2c-40d7-b4aa-ddf5e6c9cbd7",
   "metadata": {},
   "source": [
    "### Magic number\n",
    "\n",
    "Many files encode a special number in their first few bytes, which can be used to distingush the files is of a given format. Wikipedia has [a big long list of these \"magic numbers\"](https://en.wikipedia.org/wiki/List_of_file_signatures) for anyone curious. TIFF uses the value `42` for it's magic number (and BigTIFF 43)."
   ]
  },
  {
   "cell_type": "code",
   "id": "bb94e4db-7779-4ac6-a634-2917035380d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell1)"
  },
  {
   "cell_type": "markdown",
   "id": "92b84a5e-60e2-4cbf-a454-992a319acca3",
   "metadata": {},
   "source": [
    "## The Python `struct` module\n",
    "\n",
    "Note the use of the `struct` module above. This is a module from the Python stdlib that is super handy when working with binary data, as it is able to pack (Python type to binary representation) and unpack (binary representation to Python type) data values given a specific format. Packing and unpacking allow specifying the endianness of the binary data using the `>` and `<` characgters, which designate big and little endianness, respectively.\n",
    "\n",
    "The `H` in the magic number unpacking indicates that the data type is `uint16`. Some of data types we'll be working and their struct format charaters include:\n",
    "\n",
    "| Data type | Format character |\n",
    "| --------- | ---------------- |\n",
    "| `uint8`   | `B`              |\n",
    "| `char[1]` | `s`              |\n",
    "| `unit16`  | `H`              |\n",
    "| `unint32` | `I`              |\n",
    "\n",
    "Additional format characters are listed in the `DATA_TYPES` dict defined near the beginning of this notebook; also consider reviewing [the `struct` docs](https://docs.python.org/3/library/struct.html) for the full list of format codes available and other details on how to use `struct`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7831f3-186b-4402-8a41-a0c7bede61ab",
   "metadata": {},
   "source": [
    "## First IFD offset: the next four bytes\n",
    "\n",
    "Immediately following the TIFF header is the offset to the first image file directory (IFD) in the file. In a standard TIFF this offset is a 32-bit unsigned integer, as was previously alluded. We can read in and view those bytes:"
   ]
  },
  {
   "cell_type": "code",
   "id": "404bf225-d513-4899-9a20-4837ab069686",
   "metadata": {},
   "source": "# (See notes: cell2)"
  },
  {
   "cell_type": "markdown",
   "id": "4d2f41ad-cf78-4168-a1fe-dea5eb91ca63",
   "metadata": {},
   "source": [
    "Though that's not super useful until we unpack those bytes into in integer (here using `I` because the offset is a `uint32` value):"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c70828e-ef8b-4026-9c8f-ce15f13c3b11",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell3)"
  },
  {
   "cell_type": "markdown",
   "id": "ddf82ec3-a381-4a9f-9579-a8668abf34a2",
   "metadata": {},
   "source": [
    "## Parsing the Image File Directory\n",
    "\n",
    "The Image File Directory (IFD) is a data structure composed of entries called tags (hence the name \"Tag Image File Format\"). The IFD doesn't start with the first tag entry, however. It begins with a 2-byte `unit16` value indicating the number of tags within the IFD. This value enables us, along with the IFD offset within the file, to read the entire sequence of tag bytes via `file_bytes[ifd_offset + 2:ifd_offset + (tags_count * tag_size)]`.\n",
    "\n",
    "### Tag structure\n",
    "\n",
    "In a standard TIFF, tags are a 12-byte sequence (so `tag_size` above is 12 bytes) of the following structure:\n",
    "\n",
    "| Tag Bytes | Tag field name  | Field data type |\n",
    "| --------- | --------------- | --------------- |\n",
    "| 0 - 1     | `code`          | `uint16`        |\n",
    "| 2 - 3     | `data_type`     | `uint16`        |\n",
    "| 4 - 7     | `count`         | `uint32`        |\n",
    "| 8 - 11    | `value`         | `char[4]`       |\n",
    "\n",
    "In the case of BigTIFF files, each tag is a 20-byte sequence where the `count` and `value` are of type `uint64`.\n",
    "\n",
    "The tag `code` field gives us a way to find the meaning of the tag `value`, as the `code` is an integer that maps to the tag name. The Library of Congress has [a handy table](https://www.loc.gov/preservation/digital/formats/content/tiff_tags.shtml) we can use to look up the tags by their codes.\n",
    "\n",
    "#### Tag data types\n",
    "\n",
    "The tag `data_type` is also an integer value, in this case mapping to the data type we can use to interpret `value` per the following table:\n",
    "\n",
    "| `data_type` | Type Name | Data type   |\n",
    "| ----------- | --------- | ----------- |\n",
    "| 1           | BYTE      | `uint8`     |\n",
    "| 2           | ASCII     | `char[1]`   |\n",
    "| 3           | SHORT     | `uint16`    |\n",
    "| 4           | LONG      | `uint32`    |\n",
    "| 5           | RATIONAL  | `uint32[2]` |\n",
    "| 6           | SBYTE     | `int8`      |\n",
    "| 7           | UNDEFINED | `uint8`     |\n",
    "| 8           | SSHORT    | `int16`     |\n",
    "| 9           | SLONG     | `int32`     |\n",
    "| 10          | SRATIONAL | `int32[2]`  |\n",
    "| 11          | FLOAT     | `float32`   |\n",
    "| 12          | DOUBLE    | `float64`   |\n",
    "| 13          | SUBIFD    | `uint32`    |\n",
    "| 14          | n/a       | n/a         |\n",
    "| 15          | n/a       | n/a         |\n",
    "| 16          | ?         | `uint64`    |\n",
    "| 17          | ?         | `int64`     |\n",
    "| 18          | ?         | `uint64`    |\n",
    "\n",
    "(I believe data types 16, 17, and 18 are specifc to BigTIFF, but I have so far been unable to find confirmation either way.)\n",
    "\n",
    "The `count` field tells us how many of the listed `data_type` make up the `value` of the tag. Note that even a `count` of just one for a `data_type` of, say 5, or two `uint32`s would not fit in a `value` in a standard TIFF file as `value` itself is only four bytes long. Similarly, a `count` greater than 4 with a `data_type` of 1 (`uint8`) would also be larger than can fit in `value`.\n",
    "\n",
    "In such cases where `count * len_in_bytes(data_type) > 4`, `value` itself is not actually the tag value but an offset to the actual value within the file. The length of that value is given by the previous expression `count * len_in_bytes(data_type)`. Thus, to get the actual value we can read `file_bytes[value:value + (count * len_in_bytes(data_type))]`.\n",
    "\n",
    "The IFD doesn't end with the last tag either. Each IFD contains a 4-byte (`uint32`) offset to the next IFD in the file (or 8-byte `uint64` in the case of BigTIFF). In the event an IFD is the last one in the file it will have a value of 0 for its next IFD offset. As a result, it should be possible to build a map of the complete contents of a TIFF by iterating through its IFDs and parsing their tags into some appropriate hierarchical data structure (TIFF --< IFDs --< Image segments) ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffab897-313d-4edd-b2a1-3b5c8048e2d1",
   "metadata": {},
   "source": [
    "### Finding the tag count and reading the tag bytes\n",
    "\n",
    "As mentioned, an IFD starts with a 2-byte `uint16` value indicating its number of tags. If we have an IFD's offset (`ifd_offset`) within the file--which for the first IFD we know is given to us as the first bytes in the file immediately following the TIFF header--then we also know that IFS's tag offset (`tags_start`) is given by `ifd_offset + 2`.\n",
    "\n",
    "Parsing the tag count (`tags_count`) should simply be a matter of using `struct.unpack` to unpack the two tag count bytes into an integer (struct format char `H` for `uint16`). We need to make sure we use the endianness indicicated in the file header. `<` is little endian in `struct.unpack`, where `>` is big endian. Looking back, the proper endian character should have been saved into the `endianness` var for us back when we were inspecting the header bytes."
   ]
  },
  {
   "cell_type": "code",
   "id": "19362c9b-f9b5-4a96-a0f1-c1ae333f5a41",
   "metadata": {},
   "source": "# (See notes: cell4)"
  },
  {
   "cell_type": "markdown",
   "id": "bea8c45d-6197-4f04-9bd4-3290e674182c",
   "metadata": {},
   "source": [
    "If we know the tag count and the tag size (12 bytes for TIFF, 20 for BigTIFF), then we can find the total number of bytes in the IFD's tags by `tag_count * tag_size`. From this we should be able to find the last byte of the tags with `tags_end = tags_start + (tag_count * tag_size)`, allowing us to read the tag bytes (`tags_bytes`) from the file."
   ]
  },
  {
   "cell_type": "code",
   "id": "c9ad2762-0dbd-4d15-9b0c-336b0baf138d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell5)"
  },
  {
   "cell_type": "markdown",
   "id": "88a37331-72d2-457c-8c79-b160128e3fac",
   "metadata": {},
   "source": [
    "It's also important to note that we can use the `tags_end` to know the offset of the next IFD offset, which a 4-byte value we can unpack into a `uint32` (for a standard TIFF, it's uint64 for a BigTIFF). We won't use this for anything in this notebook, but it is good to know in case you want to take parsing further and go on to the other IFDs in this file."
   ]
  },
  {
   "cell_type": "code",
   "id": "ca4d52ee-30b2-47a0-8a35-3fc4af01ed45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell6)"
  },
  {
   "cell_type": "markdown",
   "id": "9d8a58ef-e3e1-47d9-83d6-e286d3d1a44c",
   "metadata": {},
   "source": [
    "### Parsing each tag\n",
    "\n",
    "To parse each tag we need to find a way to split each tag's bytes out of the of the larger bytes string. Python gives us many valid ways of doing this. Let's try using a `for` loop to split the tags bytes to see what each tag looks like."
   ]
  },
  {
   "cell_type": "code",
   "id": "6e452ccc-16cf-4898-81b9-80db88f09e4a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell7)"
  },
  {
   "cell_type": "markdown",
   "id": "e55f7bd5-b714-4190-9c67-4e8532f79e33",
   "metadata": {},
   "source": [
    "#### Unpacking the tag values\n",
    "\n",
    "The above show us we can easily extract each tag's bytes, but we next need to use `struct.unpack` to extract the tag's `code`, `data_type`, `count`, and `value` binary values into Python types. Remember that `code` and `data_type` are `uint16` values, which map to the struct `H` format. Look up the proper struct format values for `count` and `value` knowing what you know about the data types of those tag fields and verify if the format passed into `struct.unpack` in the example here is correct (feel free to consult the `DATA_TYPES` dict above or the struct docs directly).\n",
    "\n",
    "For variety, this example implementation uses a `while` loop to extract the tag bytes. Each tag's fields are added into a dictionary indexed by the tag `code` to facilitate easy access in later code."
   ]
  },
  {
   "cell_type": "code",
   "id": "3c81f0c7-8a03-49f9-b998-655c6dcb86a2",
   "metadata": {},
   "source": [
    "tags = {}\n",
    "tag_index = 0\n",
    "\n",
    "while tag_index < tags_count:\n",
    "    try:\n",
    "        tag_bytes = tags_bytes[(tag_size * tag_index) : (tag_size * (tag_index + 1))]\n",
    "        tag_index += 1\n",
    "    except IndexError:\n",
    "        break\n",
    "\n",
    "    code, data_type, count, value = struct.unpack(f'{endianness}HHI4s', tag_bytes)\n",
    "    tags[code] = {\n",
    "        'data_type': data_type,\n",
    "        'count': count,\n",
    "        'value': value,\n",
    "    }\n",
    "\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9c851-779a-4d6c-a0b2-7a43a6859a20",
   "metadata": {},
   "source": [
    "#### Understanding tag codes\n",
    "\n",
    "Now that we have TIFF tag values to look at, it would be good to mention the [Libray of Congress' guide to TIFF Tags](https://www.loc.gov/preservation/digital/formats/content/tiff_tags.shtml) again. We can use that lookup table to interpret each of the integer codes in a meaningful way. Note that some codes we will see in every file, while others may be specific to the way a file was encoded or the type of data it contains. Further, a number of the tags are specific to the GeoTIFF format and are required for such files, while some are used for metadata by GDAL and can generally be expected in a GeoTIFF (though not always of course).\n",
    "\n",
    "For example, we should always expect to see 256, 257, 258, and 259 (and others, these are just good examples):\n",
    "\n",
    "| Code | Tag Name      | Tag Description              |\n",
    "| ---- | ------------- | ---------------------------- |\n",
    "| 256  | ImageWidth    | Number of image columns      |\n",
    "| 257  | ImageLength   | Number of image rows         |\n",
    "| 258  | BitsPerSample | Number of bits in each pixel |\n",
    "| 259  | Compression   | Integer mapping to compression algorithm used for each image segment |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfe55d-23b1-4fd3-9f32-e1901542457d",
   "metadata": {},
   "source": [
    "#### Unpacking the tag values\n",
    "\n",
    "Recalling the earlier explanation about tag data types, counts, and values, we know that unpacking the tag values will not be the same for each tag given the differences in those three aforementioned tag fields across each of our different tags. For some tags that have a single count of a shorter data type we can unpack the tag `value` directly. But for longer values we'll have to use the tag `value` as an offset into the file to read the actual bytes to unpack.\n",
    "\n",
    "We'll start with one of these easier examples and unpack the image size tags 256 and 257. Check the data types for these tags. What are the struct format chars for each? Will we need to unpack all four bytes of the `value` for either of these tags?"
   ]
  },
  {
   "cell_type": "code",
   "id": "8723a085-841e-4694-879f-28cfaba90758",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell8)"
  },
  {
   "cell_type": "markdown",
   "id": "91b2dd60-3b7e-414e-8d14-ca2cca6e8aea",
   "metadata": {},
   "source": [
    "In the cases where the tag `value`'s four bytes are not sufficient to contain the whole tag value, parsing is a bit more complex. We not only need to find the struct format character (`struct_dtype`) and size for the tag's data type, but then we need to:\n",
    "\n",
    "* use the data type size and the tag `count` to calculate how many bytes we need to read (`size`)\n",
    "* unpack the `value` to get the actual value's byte offset in the file (`offset`)\n",
    "* combine `size` and `offset` to get the byte range and read that out fo the file (giving us `values`)\n",
    "* build the struct format string (`endianness + (struct_dtype * count)`) then unpack `values`\n",
    "\n",
    "We'll preview this here with an example unpacking the tile offsets tag (324). The values we get out of this (`tile_offsets`) are the byte offsets for each image segment (tile) in the image represented by this IFD. We will be able to use these offsets in the next section to read the specific tile containing our POI (though we'll have unpack the rest of our tags and do a bit of math to figure out which one and what to do with the bytes)."
   ]
  },
  {
   "cell_type": "code",
   "id": "75e6e581-3a51-444a-b90f-20d94e19fc41",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tag = tags[324]\n",
    "struct_dtype = DATA_TYPES[tag['data_type']]\n",
    "size = tag['count'] * struct.calcsize(struct_dtype)\n",
    "offset = struct.unpack(f'{endianness}I', tag['value'])[0]\n",
    "values = url_read_bytes(href, offset, offset+size)\n",
    "tile_offsets = struct.unpack(endianness + (struct_dtype * tag['count']), values)\n",
    "\n",
    "for idx, tile_offset in enumerate(tile_offsets):\n",
    "    print(f\"Offset tile {idx}: {tile_offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde6490-a49f-4014-b981-035e7ff5c170",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Refer back to the STAC item and see if the `file` STAC extension is in use. Is the file size listed for the COG asset your are examining, and if so how close to the end of the file do these tiles appear to get?\n",
    "* Can you use the unpacking examples to create a generalized approach to unpacking the tag values and apply that to the rest of the tags in the IFD? The next section will have you unpack all the tags, so finding a quick an efficient way to do this might be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc1666-70bb-4486-9b6a-5f3768f0b278",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reading a tile from the image\n",
    "\n",
    "Read the tile intersecting our POI will require most of our tags to be unpacked and decoded. Refer back to the tags dictionary `tags` keys for the list of all tag codes in our TIFF's first IFD and the above documentation on the tag codes. Unpack each tag's value into the corresponding variable name in the list below:\n",
    "\n",
    "* `image_width`\n",
    "* `image_length`\n",
    "* `bits_per_sample`\n",
    "* `compression`\n",
    "* `samples_per_pixel`\n",
    "* `predictor`\n",
    "* `tile_width`\n",
    "* `tile_length`\n",
    "* `tile_offsets`\n",
    "* `tile_byte_counts`\n",
    "* `sample_format`\n",
    "* `pixel_scale`\n",
    "* `tie_point`\n",
    "* `geo_key_directory`\n",
    "* `geo_double_params` (if defined, else `tuple()`)\n",
    "* `geo_ascii_params` (if defined, else `b''`)\n",
    "* `gdal_metadata`\n",
    "* `nodata_value`\n",
    "\n",
    "**NOTE**: if you have chosen a different COG source than the default Sentinel 2 red band from Earth Search, you might need to consider additional tags and processing to get this part to work. TIFF is an extremely flexible format, but this means it has many different cases that need to be handled to be able to read any arbitrary file (which also means some atypical features supported by one implementation might lead to incompatibilities with other implementations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76f347-7613-4556-ae6a-99f2fc3da835",
   "metadata": {},
   "source": [
    "### Let's define a function to make upacking the tags easier\n",
    "\n",
    "We have a lot of tags to unpack. For the sake of time, here's a function that we can use to make unpacking all the tags easier."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3b3adbe-e6cb-400e-ba52-e87fc8f3a6ad",
   "metadata": {},
   "source": [
    "class TagDict(TypedDict):\n",
    "    data_type: int\n",
    "    count: int\n",
    "    value: bytes\n",
    "\n",
    "type TagsDict = dict[int: TagDict]\n",
    "\n",
    "def unpack_tag(tag: TagsDict, endianness: Literal['>', '<']) -> Any:\n",
    "    struct_dtype = DATA_TYPES[tag['data_type']]\n",
    "    size = tag['count'] * struct.calcsize(struct_dtype)\n",
    "    value = tag['value']\n",
    "\n",
    "    offset = None\n",
    "    if size > len(value):\n",
    "        offset = struct.unpack(endianness + 'I', value)[0]\n",
    "        value = url_read_bytes(href, offset, offset+size)\n",
    "        \n",
    "    unpacked = struct.unpack(endianness + (struct_dtype * tag['count']), value[:size])\n",
    "\n",
    "    # if data_type == 2 (ASCII) we want to join the chars together\n",
    "    if tag['data_type'] == 2:\n",
    "        return b''.join(unpacked)\n",
    "    elif tag['count'] == 1:\n",
    "        return unpacked[0]\n",
    "    return unpacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0d5cdb-eb90-4e28-8be7-3d32e9604983",
   "metadata": {},
   "source": [
    "Let's try that out on the tags we unpacked above and see how this works!"
   ]
  },
  {
   "cell_type": "code",
   "id": "5513363f-b227-4019-8e25-d36359e97757",
   "metadata": {},
   "source": "# (See notes: cell9)"
  },
  {
   "cell_type": "code",
   "id": "6d2665c2-85b1-4af9-a194-9e439711b6b4",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell10)"
  },
  {
   "cell_type": "markdown",
   "id": "989ad65f-bab8-442a-9d04-a1849c60c96c",
   "metadata": {},
   "source": [
    "Now let's use that function to unpack all our tags into the corresponding variable."
   ]
  },
  {
   "cell_type": "code",
   "id": "ca0ec6a1-3724-4fa7-ad23-c2be84b5bd50",
   "metadata": {},
   "source": [
    "image_width = unpack_tag(tags[256], endianness)\n",
    "image_length = unpack_tag(tags[257], endianness)\n",
    "bits_per_sample = unpack_tag(tags[258], endianness)\n",
    "compression = unpack_tag(tags[259], endianness)\n",
    "samples_per_pixel = unpack_tag(tags[277], endianness)\n",
    "predictor = unpack_tag(tags[317], endianness)\n",
    "tile_width = unpack_tag(tags[322], endianness)\n",
    "tile_length = unpack_tag(tags[323], endianness)\n",
    "tile_offsets = unpack_tag(tags[324], endianness)\n",
    "tile_byte_counts = unpack_tag(tags[325], endianness)\n",
    "sample_format = unpack_tag(tags[339], endianness)\n",
    "pixel_scale = unpack_tag(tags[33550], endianness)\n",
    "tie_point = unpack_tag(tags[33922], endianness)\n",
    "geo_key_directory = unpack_tag(tags[34735], endianness)\n",
    "geo_double_params = tuple()  # we don't have any double params in this image\n",
    "geo_ascii_params = unpack_tag(tags[34737], endianness)\n",
    "gdal_metadata = unpack_tag(tags[42112], endianness)\n",
    "original_nodata_value = unpack_tag(tags[42113], endianness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f1870-d918-4bbb-be17-147392f10736",
   "metadata": {},
   "source": [
    "### Interpreting tag values\n",
    "\n",
    "Many of the tags are straightforward. Some are enumerations which require an external lookup table. Others require cross-references between their values to make sense of the contents. Let's take a look at the few that are not straightforward to understand.\n",
    "\n",
    "#### Compression\n",
    "\n",
    "The `compression` tag value represents one of an enumerated set of possible compression methods. Continuing with the spirit of needing to consult various external lookup tables, the [Wikipedia entry for TIFF has a great table of possible compression formats and their integer values](https://en.wikipedia.org/wiki/TIFF#TIFF_Compression_Tag) is a great resource for understanding the meaning of the different possible values.\n",
    "\n",
    "**Question**: What is the value of the `compression` tag and what compression scheme does it indicate?"
   ]
  },
  {
   "cell_type": "code",
   "id": "e458b1cf-d6e0-4195-b05d-735ce40c97f8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell11)"
  },
  {
   "cell_type": "markdown",
   "id": "5f68597c-873d-403a-80bc-e58a245f13cb",
   "metadata": {},
   "source": [
    "#### Sample format\n",
    "\n",
    "The `sample_format` tag value represents one of an enumerated set of possible data types. Those values map as follows:\n",
    "\n",
    "| Format Value | Data Type |\n",
    "| ------------ | --------- |\n",
    "| 1 | `uint`   |\n",
    "| 2 | `int`    |\n",
    "| 3 | `float`  |\n",
    "| 4 | untyped  |\n",
    "| 5 | `cint`   |\n",
    "| 6 | `cfloat` |\n",
    "\n",
    "The bit depth of the specified format is dependent on the value of the `bits_per_sample` tag."
   ]
  },
  {
   "cell_type": "code",
   "id": "d9f18e5b-05a3-4153-a010-16b589e31bd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": "# (See notes: cell12)"
  },
  {
   "cell_type": "markdown",
   "id": "f03ffc5c-74f8-4d9e-ae1d-c10306b34a4b",
   "metadata": {},
   "source": [
    "**Question**: What does the value of the `sample_format` tag indicate with regards to the data type and length of the cell values in this image (e.g., `uint32`, `int8`, `float32`, etc.)? What does this data type map to in the struct format characters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73190c20-4600-45fb-9df8-333a9b4d050f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Pixel scale and tie point\n",
    "\n",
    "The `pixel_scale` tag is part of the GeoTIFF specification. It is a three-tuple where each value represents one dimension of the pixel scale, specifically the x, y, and z scales, respectively. In other words, each of the scale values represent the change in coordinate from one pixel origin to the next along the specified dimension. The units of each scale value are the same as those specified in coordinate reference system (CRS; we'll see this when reviewing the `geo_key_directory` below).\n",
    "\n",
    "The `tie_point` tag is again a member of the GeoTIFF specification. It defines a set of coordinates in the image space and their mappings to coordinates in the model space as a list of six-tuples. The first three tuple values are the image space x, y, and z coordinates, respectively. The latter three tuple values are the model space x, y, and z, respectively. The model space is perhaps best understood to be the coordinate reference system defined for the image.\n",
    "\n",
    "What is most notable for us about these two tags is that we can use them to build a simple affine transform to convert between image space and model space. Most GeoTIFF files, like ours, use such an affine transform, which means the following is frequently true:\n",
    "\n",
    "* the set of coordinate mappings has length one, i.e., only one point is mapped from image space to coordinate space\n",
    "* the image space coordinates of that point are (0, 0, 0), which effectively allows us to consider the model space coordiantes to be the geographic point represented by the image origin\n",
    "\n",
    "The [GeoTIFF spec docs detailing how to use these values are here](http://geotiff.maptools.org/spec/geotiff2.6.html). Note that the `pixel_scale` tag is optional; in some cases a `ModelTransformationTag` is used instead to encode the affine transformation matrix into the file, such as when needing to express grid rotation. Sometimes neither of these tags are present, such as when the transformation is not affine, which is typically when the `tie_point` tag would have multiple points describing a warp mesh over the image. Consult the docs to fully understand the interactions of these three tags and how to interpret their values outside this simple affine case.\n",
    "\n",
    "Why does all of this matter for us? We can use the `pixel_scale` and `tie_point` tag values to construct an affine transform object, which we'll use to perform coordinate transformations between model space (the image CRS) and image space (pixel coordinates). We need to be able to do this to find what pixel in the image contains our POI, so we can find which image tile to read."
   ]
  },
  {
   "cell_type": "code",
   "id": "468f9c52-6890-4fba-b056-020bb6e380f1",
   "metadata": {},
   "source": [
    "transform = Affine(\n",
    "    # w-e pixel resolution / pixel width\n",
    "    pixel_scale[0],\n",
    "    # row rotation (typically zero)\n",
    "    0,\n",
    "    # x-coordinate of the upper-left corner of the upper-left pixel (origin)\n",
    "    tie_point[3] - (pixel_scale[0] * tie_point[0]),\n",
    "    # column rotation (typically zero)\n",
    "    0,\n",
    "    # n-s pixel resolution / pixel height (negative value for a north-up image)\n",
    "    -pixel_scale[1],\n",
    "    # y-coordinate of the upper-left corner of the upper-left pixel (origin)\n",
    "    tie_point[4] - (-pixel_scale[1] * tie_point[1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46017e-0bf0-4a4f-bea5-61a23729c884",
   "metadata": {},
   "source": [
    "#### Geo key directory and the params\n",
    "\n",
    "Another set of GeoTIFF-spec tags, `geo_key_directory`, `geo_double_params`, and `geo_ascii_params` represent a collection of geospatial information we need to interpret the data in a spatially-aware way. For example, such important information as the CRS is stored amongst these tags. The [GeoTIFF spec docs also document these tags and their interactions](http://geotiff.maptools.org/spec/geotiff2.4.html).\n",
    "\n",
    "In short, `geo_double_params` and `geo_ascii_params` are actually sets of parameters that can be used to fill in information that cannot be represented directly in the `geo_key_directory` due to data type differences (the latter is a `uint16` tuple whereas the former two are tuples of double precision floats and ASCII-encoded strings, respectively). The `geo_key_directory` is a collection of four-tuples (potentially with some additional trailing values), the first of which is a header that documents the tuples that follow. It has the following 8-byte structure:\n",
    "\n",
    "```\n",
    "Header = (KeyDirectoryVersion, KeyRevision, MinorRevision, NumberOfKeys)\n",
    "```\n",
    "\n",
    "For our purposes, the important piece here are the number of keys: we need to know how many keys are in the directory to be able to work out the offset to any additional values in the directory structure we might need to fill in directory entries that have multiple `unit16` values.\n",
    "\n",
    "After the header, each of the keys in the directory have the 8-byte structure:\n",
    "\n",
    "```\n",
    "KeyEntry = (KeyID, TIFFTagLocation, Count, Value_Offset)\n",
    "```\n",
    "\n",
    "The `KeyID` here is just like our TIFF tags: it is an identifier that can be used with an external lookup table to interpret the meaning of the key's value. The `TIFFTagLocation` is used to point to a TIFF tag that contains the value for this key: if the value is directly embedded in the key (in the place of `Value_Offset`) then the location is `0` and this key's value is of type `uint16`. In cases where the value is not directly embedded in the key the location will have the value of the tag code that contains the value. The `Value_Offset` and `Count` can then be used to extract the set of values pertaining to this key from that tag's data. The data type of the key value is given by the source tag's data type.\n",
    "\n",
    "For example, if we have a key entry with the values `(1024, 0, 1, 1)` we know that the key ID is `1024`, the location of `0` means the value is embedded in the key entry, and that means our count is necessarily `1` and we can interpret the `Value_Offset` as the key value, in this case `1`.\n",
    "\n",
    "A more complex example could be like `(2049, 34737, 7, 22)`: in this case we have a non-zero location, so we have to read the values--in this case seven values per the count value--from a separate tag. The location of `34737` corresponds to the `geo_ascii_params` tag, which not only tells us where to get the values for this key, but also their data type. If we have a value of the `34737` tag of `b'WGS 84 / UTM zone 10N|WGS 84|\\x00'`, then taking 7 bytes from position 22 we end up with `b'WGS 84|'`. The `|` is intended to be converted into a null byte to terminate the extracted string; in Python it is easy enough to read one less byte than the key's count for ASCII-type keys as string termination is handled for us.\n",
    "\n",
    "We can use the above explanation to write a general-purpose function to extract the keys into a dict, like we originally did with the IFD tags, and then we can use it to extract our keys. Refer to the [GeoTIFF document \"Geocoding Raster Data\"](http://geotiff.maptools.org/spec/geotiff2.7.html#2.7) for and explanantion of the key IDs and how to understand their meanings. These keys are critical for finding the CRS of the file via the information presented in that documentation."
   ]
  },
  {
   "cell_type": "code",
   "id": "79bf68fb-ee82-4f40-8fb7-e02618a55968",
   "metadata": {},
   "source": [
    "def extract_geo_keys(\n",
    "    key_directory: tuple[int, ...],\n",
    "    double_params: tuple[float, ...],\n",
    "    ascii_params: bytes,\n",
    ")-> dict[int, int | float | bytes]:\n",
    "    keys: dict[int, int | float | bytes] = {}\n",
    "    \n",
    "    try:\n",
    "        _, _, _, key_count = key_directory[0:4]\n",
    "        for key_index in range(key_count):\n",
    "            offset = (4 * key_index) + 4\n",
    "            key_id, location, count, value_offset = key_directory[offset:offset + 4]\n",
    "            \n",
    "            if location == 0:\n",
    "                keys[key_id] = value_offset\n",
    "            elif location == 34735:\n",
    "                keys[key_id] = key_directory[value_offset:value_offset + count]\n",
    "            elif location == 34736:\n",
    "                keys[key_id] = double_params[value_offset:value_offset + count]\n",
    "            elif location == 34737:\n",
    "                keys[key_id] = ascii_params[value_offset: value_offset + (count - 1)]\n",
    "            else:\n",
    "                raise ValueError(f'Unknown location: {location}')\n",
    "    except:\n",
    "        raise ValueError('Could not parse geo keys')\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ab7a95e-5198-4d42-9d99-aa0e15df32d4",
   "metadata": {},
   "source": [
    "geo_keys = extract_geo_keys(geo_key_directory, geo_double_params, geo_ascii_params)\n",
    "geo_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51045882-2605-4cea-90ce-18d63c6dc5a7",
   "metadata": {},
   "source": [
    "**Question**: From the extracted geo key values, can you find the CRS and it's EPSG code?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64deb076-42f0-47af-891b-611b29668dc2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### Nodata\n",
    "\n",
    "The GDAL nodata value is stored in GeoTIFFs as a null-terminated ASCII string, for some reason (likely to ensure it can be parsed with a consistent data type, in particular because the nodata value needs to be interpreted with the data type of the TIFF data, which might not map directly to the TIFF-defined data types). Because of this, the `nodata` value needs some additional processing before we can use it.\n",
    "\n",
    "Specifically, we need to clip the final character off, then we need to cast it to an appropropriate data type (as given by `sample_format` and `bits_per_sample`). For example, if we have an integer data type for our image data then we need to do something like `nodata_value = int(original_nodata_value[:-1])`."
   ]
  },
  {
   "cell_type": "code",
   "id": "b0d5e38a-c480-4433-a8f6-4fd2e3e9bb25",
   "metadata": {},
   "source": [
    "# We need to clip the string terminator off the nodata value\n",
    "# before coercing to an int (because it is stored as ASCII)\n",
    "nodata_value = int(original_nodata_value[:-1])\n",
    "nodata_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d92de-223e-4f31-89bd-f07c85b67633",
   "metadata": {},
   "source": [
    "## Reading an image tile\n",
    "\n",
    "Now that we have all our metadata parsed out we can focus on using that metadata to read a tile. We have our POI though, so we presumably want to find the tile containing said POI, rather than some other arbitrary tile. To do so we'll need to do some math.\n",
    "\n",
    "### Transforming our POI\n",
    "\n",
    "First, we need to find the point coordinates of our POI in the same reference system as the image. We can use the `to_crs` method on our POI with our image's CRS as parsed from the geo keys above."
   ]
  },
  {
   "cell_type": "code",
   "id": "a5cf3beb-6206-4101-85f5-332a8541692e",
   "metadata": {},
   "source": [
    "image_crs = f\"EPSG:{geo_keys[3072]}\"\n",
    "POI_proj = POI.to_crs(image_crs)\n",
    "print(f'x={POI_proj.geom.x}, y={POI_proj.geom.y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842480d-530b-427d-aafc-1268255e021f",
   "metadata": {},
   "source": [
    "Check the above output. Does it make sense given what we know about the origin of our image, and the relation of our POI to the image footprint?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b166f9-13e2-4084-b59c-51bd536e33cb",
   "metadata": {},
   "source": [
    "### Finding the pixel coordinates of our POI\n",
    "\n",
    "Now that we have our POI geographic coordinates in the same CRS as our image, we can use the image's affine transform to convert our POI's geographic coordinates into pixel coordinates in our image's pixel grid. The author of this notebook has created a small library to make tasks involving raster grids with affine transforms easier, called `griffine`. We can make an instance of a `griffine.Grid` and attach our transform to it, which will help us in a number of operations to come. Then we can use the grid to find the cell containing our point."
   ]
  },
  {
   "cell_type": "code",
   "id": "0109cd09-b524-4d7e-887e-914fe02ce9ca",
   "metadata": {},
   "source": [
    "grid = Grid(rows=image_length, cols=image_width).add_transform(transform)\n",
    "cell = grid.point_to_cell(POI_proj)\n",
    "print(f'row={cell.row}, col={cell.col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c9a1fd-a759-4683-93cb-38303d6a74f8",
   "metadata": {},
   "source": [
    "Again, check the above output. Does it make sense given what we know about the origin of our image, its grid, and the relation of our POI to the image footprint?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29697e92-2742-4154-883b-1fefa11285b3",
   "metadata": {},
   "source": [
    "### Finding our tile coordinates\n",
    "\n",
    "To work out which tile we need to read we need to convert our pixel coordinates into tile coordinates. We can tile our `grid` object and get the tile containing our POI."
   ]
  },
  {
   "cell_type": "code",
   "id": "aad7b663-79ac-48fc-ba80-68d5adbeccd3",
   "metadata": {},
   "source": [
    "tile_grid = grid.tile_via(Grid(rows=tile_length, cols=tile_width))\n",
    "tile = tile_grid.point_to_tile(POI_proj)\n",
    "print(f'tile_row={tile.row}, tile_col={tile.col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91d35d4-294c-44da-93c9-0d9152f97ac9",
   "metadata": {},
   "source": [
    "One last time: check the above output. Does it make sense given what we know about the structure our image, and the relation of our POI to the image footprint?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788a090-6288-4925-963d-5e255cff3621",
   "metadata": {},
   "source": [
    "### Finding our tile offset and byte length\n",
    "\n",
    "The tag values of `tile_offsets` and `tile_byte_counts` give us the offset and byte lengths of each tile. To retrive them for a given tile we need to know the tile's index within those tuples. We use our `tile` object with our `tile_grid` to fine the tile's linear index within the grid."
   ]
  },
  {
   "cell_type": "code",
   "id": "a56f428e-3fc3-4e43-a660-4ca0d5277818",
   "metadata": {},
   "source": [
    "tile_index = tile_grid.linear_index(tile)\n",
    "tile_offset = tile_offsets[tile_index]\n",
    "tile_byte_length = tile_byte_counts[tile_index]\n",
    "print(f'tile ({tile.row}, {tile.col}) has index {tile_index} and is at offset {tile_offset} with length {tile_byte_length}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade2970-ee62-40f4-bbaf-012a504c330f",
   "metadata": {},
   "source": [
    "### Actually reading the tile\n",
    "\n",
    "Now that we know where the tile bytes are in the file we can read them, extract them (using the specified `compression`), then unpack them into a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "id": "06aec812-f6f1-4339-96e9-2d803b6e5649",
   "metadata": {},
   "source": [
    "tile_bytes = url_read_bytes(href, tile_offset, tile_offset + tile_byte_length)"
   ]
  },
  {
   "cell_type": "code",
   "id": "55db4c1d-ac5b-4596-b5c2-a71127f6c104",
   "metadata": {},
   "source": [
    "# Per our `compression` tag we know we the data is compressed using `DEFLATE`,\n",
    "# which can be extracted using the stdlib `zlib` module.\n",
    "import zlib\n",
    "tile_extracted = zlib.decompress(tile_bytes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "id": "73a34ce2-5380-4669-a498-75c0f8d100c2",
   "metadata": {},
   "source": [
    "# Our data type is `uint16` as we previously found; using our\n",
    "# lookup table we know that maps to a struct format char of `H`.\n",
    "# That dtype is 2-bytes in length, so we know our tile data\n",
    "# contains `len(tile_extracted) // 2` pixel values.\n",
    "struct_dtype = 'H'\n",
    "tile_array = np.array(\n",
    "    struct.unpack(\n",
    "        endianness + (struct_dtype * (len(tile_extracted) // struct.calcsize(struct_dtype))),\n",
    "        tile_extracted,\n",
    "    ),\n",
    "    dtype=np.uint16\n",
    ").reshape(tile_width, tile_length)\n",
    "tile_array"
   ]
  },
  {
   "cell_type": "code",
   "id": "af3f8da5-6364-4443-994e-3fcc5570c9e4",
   "metadata": {},
   "source": [
    "# Or, more easily but perhaps too abstractly\n",
    "np.frombuffer(tile_extracted, dtype=np.uint16).reshape(tile_width, tile_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c76df-928c-4561-8b74-ad49ea92022f",
   "metadata": {},
   "source": [
    "#### A note on `predictor`\n",
    "\n",
    "The `predictor` tag is used when a filtering step is done prior to compression. For geospatial data, values of `2` and `3` are common, `2` is best for integer data, and calculates the horizontal difference between cells. `3` is used for floating point data. In other words, if we have a predictor set and it isn't `1` (indicating no predictor) then we can't just extract the data and start using it. The data will require processing step to reverse the prediction operation and restore the data back to its original values."
   ]
  },
  {
   "cell_type": "code",
   "id": "106632b4-0d93-42f2-97e3-c1d6a338b0a6",
   "metadata": {},
   "source": [
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "id": "0094e1f2-cb8d-4f1a-bbc8-de44eb2aed38",
   "metadata": {},
   "source": [
    "# as our data is using predictor `2` (horizontal difference),\n",
    "# we'll need to reverse the difference using a cumulative sum\n",
    "tile_array_unfiltered = np.cumsum(tile_array, axis=1, dtype=tile_array.dtype)\n",
    "tile_array_unfiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2884f5-abce-4e5f-8290-62c4a35f9dbf",
   "metadata": {},
   "source": [
    "#### Scale and offset\n",
    "\n",
    "We have yet one more operation we need to do to our data array to make it usable. It turns out the stored data format `uint16` isn't actually the real data format. Instead, limited-precision floats have been mapped to that data type by using a specified scaling factor. Moreover, due to the Sentinel 2 L2 atmospheric correction process, it's possible to have negative values in the data, which must be accounted for by shifting the uint values via a specified offset.\n",
    "\n",
    "Both the `scale` and `offset` values are contained within the `gdal_metadata` tag. The GDAL metadata format is, sadly, XML, though for our purposes it is readable enough we don't need to worry about parsing complexities, we can just print out the value of that tag and read out the values we need."
   ]
  },
  {
   "cell_type": "code",
   "id": "806d7cb4-928d-45fa-bbc2-8c1b2ab020b4",
   "metadata": {},
   "source": [
    "gdal_metadata"
   ]
  },
  {
   "cell_type": "code",
   "id": "043b1c67-8708-4549-a4b1-d2b434035d7c",
   "metadata": {},
   "source": [
    "# fill in the value_offset and value_scale from the above\n",
    "value_offset = -0.1\n",
    "value_scale = 0.0001\n",
    "tile_array_scaled_offset = (tile_array_unfiltered * value_scale) + value_offset\n",
    "tile_array_scaled_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d22864-6684-47c4-b533-fdd0ffc5bdd3",
   "metadata": {},
   "source": [
    "## Visualizing the tile on our map\n",
    "\n",
    "Now that we have our tile data, it would be great to see it alongside our POI to visually confirm we got the tile we expected. It turns out Folium has a kinda hokey way of converting numpy arrays to PNGs for display on the map, which we can leverage here to visually verify the data we've read for our tile and the operations we've done on it. It's not perfect, as it assumes our data is aligned to the mercator grid (which it probably isn't), but it's close enough for us to take a look.\n",
    "\n",
    "We just need the tile's min and max latitude and longitude (in EPSG:4326 coordinates) so we can tell Folium it's bounding box (roughly), then we can (re-)make our map and add our layers. We can use our `tile` object to compute those coordinates in our image CRS then convert them to EPSG:4326."
   ]
  },
  {
   "cell_type": "code",
   "id": "1f6b0cf7-a1bc-4743-b8c5-126aef69ce58",
   "metadata": {},
   "source": [
    "tile_origin_x, tile_origin_y  = point(*tile.origin.coords[0], crs=image_crs).to_crs(EPSG_4326).coords[0]\n",
    "tile_antiorigin_x, tile_antiorigin_y  = point(*tile.antiorigin.coords[0], crs=image_crs).to_crs(EPSG_4326).coords[0]\n",
    "\n",
    "# we make a whole new map because if we screwed\n",
    "# something up we only have to re-run this cell to fix it\n",
    "raster_map = POI.explore(name='point')\n",
    "\n",
    "stac_item_layer.add_to(raster_map)\n",
    "raster_map.fit_bounds(stac_item_layer.get_bounds())\n",
    "\n",
    "folium.raster_layers.ImageOverlay(\n",
    "    tile_array_scaled_offset,\n",
    "    bounds=[[tile_antiorigin_y, tile_origin_x], [tile_origin_y, tile_antiorigin_x]],\n",
    "    name='tile',\n",
    ").add_to(raster_map)\n",
    "\n",
    "folium.LayerControl().add_to(raster_map)\n",
    "\n",
    "raster_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f709856-e51b-41fe-9936-adc0139d1ab3",
   "metadata": {},
   "source": [
    "## Additional exercises to consider later\n",
    "\n",
    "* Find how many overviews are in this file.\n",
    "* Find the dimensions and gsd of each overview.\n",
    "* Repeat reading the tile containing your point of interest, but do so from one of the overviews.\n",
    "* How can we make reading the file more efficient? Can we get all the IFDs in the file with a single read without having to read in image data?\n",
    "* Can you write the TIFF for the map visualization yourself instead of using an external lib?\n",
    "* Repeat these exercises with a multiband TIFF to see how the file structure differs to support the additional bands.\n",
    "\n",
    "Any other cool ideas? Let me know and/or share with the group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400cd145-9b17-4369-a7fb-ec7a7f38cb69",
   "metadata": {},
   "source": [
    "## Appendix: example TIFF metadata parser\n",
    "\n",
    "Could we take parsing another step further, to better facilitate the above exercises? Wouldn't it be great if we could parse the tags into a complete objects? What if we could start with just a reference to the TIFF itself, and have an entire data structure built up to parse all the IFDs out of the file in one go?\n",
    "\n",
    "Turns out this is a fun problem and I wanted to code up a solution. Here's my attempt; what might yours look like?"
   ]
  },
  {
   "cell_type": "code",
   "id": "5ab0782e-bc93-4280-9872-71b983ca77f3",
   "metadata": {},
   "source": [
    "class Endianness(bytes, enum.Enum):\n",
    "    BIG_ENDIAN = b'MM'\n",
    "    LITTLE_ENDIAN = b'II'\n",
    "\n",
    "    @property\n",
    "    def unpack_char(self: Self) -> str:\n",
    "        match self:\n",
    "            case Endianness.BIG_ENDIAN:\n",
    "                return '>'\n",
    "            case Endianness.LITTLE_ENDIAN:\n",
    "                return '<'\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TIFFBytes:\n",
    "    data: bytes\n",
    "    endianness: Endianness\n",
    "\n",
    "    def unpack(self: Self, format: str) -> tuple[Any, ...]:\n",
    "        return struct.unpack(f'{self.endianness.unpack_char}{format}', self.data)\n",
    "\n",
    "    def chunk(self: Self, chunk_size) -> Iterator[Self]:\n",
    "        if len(self) % chunk_size != 0:\n",
    "            raise ValueError(\n",
    "                f'Cannot chunk data exactly into {chunk_size}: length {len(self)}',\n",
    "            )\n",
    "        yield from (\n",
    "            self[chunk_index * chunk_size:(chunk_index * chunk_size) + chunk_size]\n",
    "            for chunk_index in range(len(self)//chunk_size)\n",
    "        )\n",
    "\n",
    "    def __len__(self: Self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self: Self, key: int | slice) -> Self:\n",
    "        return type(self)(\n",
    "            data=self.data[key],\n",
    "            endianness=self.endianness,\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Tag:\n",
    "    code: int\n",
    "    data_type: int\n",
    "    count: int\n",
    "    value: Any\n",
    "    raw: TIFFBytes = dataclasses.field(repr=False)\n",
    "    offset: int | None = dataclasses.field(default=None, repr=False)\n",
    "\n",
    "    @classmethod\n",
    "    def from_bytes(\n",
    "        cls: type[Self],\n",
    "        tiff: TIFFMeta,\n",
    "        tag_bytes: TIFFBytes,\n",
    "    ) -> Self:\n",
    "        code, data_type, count = tag_bytes[:8].unpack('HHI')\n",
    "        offset, raw, unpacked = cls.unpack_tag_value(tiff, data_type, count, tag_bytes[8:])\n",
    "        return cls(\n",
    "            code=code,\n",
    "            data_type=data_type,\n",
    "            count=count,\n",
    "            value=unpacked,\n",
    "            raw=raw,\n",
    "            offset=offset,\n",
    "        )\n",
    "\n",
    "    def pack(self: Self, offset: int | None = None) -> bytes:\n",
    "        struct_dtype = DATA_TYPES[data_type]\n",
    "        packed = struct.pack\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def unpack_tag_value(tiff: TIFFMeta, data_type: int, count: int, value: TIFFBytes) -> tuple[int | None, bytes, Any]:\n",
    "        struct_dtype = DATA_TYPES[data_type]\n",
    "        size = count * struct.calcsize(struct_dtype)\n",
    "\n",
    "        offset = None\n",
    "        if size > len(value):\n",
    "            offset = value.unpack('I')[0]\n",
    "            value = tiff.read_bytes(offset, offset+size)\n",
    "\n",
    "        unpacked = value[:size].unpack(str(count) + struct_dtype)\n",
    "\n",
    "        # if data_type == 2 (ASCII) we want to join the chars together\n",
    "        if data_type == 2:\n",
    "            return offset, value, b''.join(unpacked)\n",
    "        elif count == 1:\n",
    "            return offset, value, unpacked[0]\n",
    "        return offset, value, unpacked\n",
    "\n",
    "\n",
    "class Tags(dict[int, Tag]):\n",
    "    @classmethod\n",
    "    def from_tags(cls: type[Self], tags: list[Tag]) -> Self:\n",
    "        return cls((t.code, t) for t in tags)\n",
    "\n",
    "    @classmethod\n",
    "    def from_tiff_bytes(cls: type[Self], tiff: TIFFMeta, tags_bytes: TIFFBytes) -> Self:\n",
    "        return cls.from_tags([Tag.from_bytes(tiff, tag_bytes) for tag_bytes in tags_bytes.chunk(12)])\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class IFD:\n",
    "    offset: int\n",
    "    tags: Tags\n",
    "    next_offset: int\n",
    "\n",
    "    @classmethod\n",
    "    def from_tiff_offset(cls: type[Self], tiff: TIFFMeta, offset: int) -> Self:\n",
    "        tags_start = offset + 2\n",
    "        tags_count = tiff.read_bytes(offset, tags_start).unpack('H')[0]\n",
    "        tags_end = tags_start + (tags_count * tag_size)\n",
    "        tags_bytes = tiff.read_bytes(tags_start, tags_end)\n",
    "        next_offset = tiff.read_bytes(tags_end, tags_end + 4).unpack('I')[0]\n",
    "        \n",
    "        return cls(\n",
    "            offset=offset,\n",
    "            tags=Tags.from_tiff_bytes(tiff, tags_bytes),\n",
    "            next_offset=next_offset,\n",
    "        )\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TIFFMeta:\n",
    "    '''Class to help parse TIFF IFDs. Only supports standard TIFFs, not BigTIFF.'''\n",
    "    href: str\n",
    "    endianness: Endianness\n",
    "    ifds: list[IFD]\n",
    "    \n",
    "    # We can track the max byte read to parse out IFD stuff.\n",
    "    # This could be an interesting data point to learn how to better optimize reads.\n",
    "    max_ifd_byte: int = 0\n",
    "    \n",
    "    def __init__(self: Self, href: str) -> None:\n",
    "        self.href = href\n",
    "\n",
    "        # we don't use self.read_bytes yet because we don't have endianness\n",
    "        __bytes = url_read_bytes(self.href, 0, 8)\n",
    "        self.max_ifd_byte = 8\n",
    "        self.endianness = Endianness(__bytes[0:2])\n",
    "\n",
    "        _bytes = TIFFBytes(data=__bytes, endianness=self.endianness)\n",
    "        \n",
    "        magic_number = _bytes[2:4].unpack('H')[0]\n",
    "        if magic_number != 42:\n",
    "            raise TypeError(f\"Unsupported file type: magic number {magic_number} != 42\")\n",
    "        \n",
    "        self.ifds: list[IFD] = []\n",
    "        ifd_offset = _bytes[4:8].unpack('I')[0]\n",
    "        while ifd_offset:\n",
    "            ifd = self.parse_ifd(ifd_offset)\n",
    "            self.ifds.append(ifd)\n",
    "            ifd_offset = ifd.next_offset\n",
    "\n",
    "    def read_bytes(self: Self, start: int, end: int) -> TIFFBytes:\n",
    "        # Note that reading for each byte range we want is terribly inefficient.\n",
    "        # We could instead use some sort of filelike object that will read and cache\n",
    "        # larger chunks of the file, as needed to accommodate requested byte ranges.\n",
    "        # Of course if we wanted to read the whole file this way we'd need to be careful\n",
    "        # of the memory requirements of such a solution.\n",
    "        self.max_ifd_byte = max(self.max_ifd_byte, end)\n",
    "        return TIFFBytes(\n",
    "            data=url_read_bytes(self.href, start, end),\n",
    "            endianness=self.endianness,\n",
    "        )\n",
    "\n",
    "    def parse_ifd(self: Self, offset: int) -> IFD:\n",
    "        return IFD.from_tiff_offset(self, offset)"
   ]
  },
  {
   "cell_type": "code",
   "id": "914616f5-c98c-41ab-b0be-eed94d0e5b89",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "tiff_meta = TIFFMeta(href)\n",
    "pprint(tiff_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a477819c-18ad-4ab5-a47a-d5a7aba5113a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### A note about `tiff_meta.max_ifd_byte`\n",
    "\n",
    "After parsing all IFDs in the file, including reading and unpacking all the tags, we see that the max byte read from the file (`max_ifd_byte`) is merely 4208. Thus we could be pretty sure, even for a an absolutely huge TIFF file, that reading something like the first 1-2 MB of file data would give us the entire set of IFDs. We could use this insight to make our reader more efficient: if we made only one read request to for the first 1-2 MB of the file, we could be pretty certain we could parse the IFD without having to incur the penalty of any further network round trips, at least until we are ready to retrive image data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "exercise_version": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}